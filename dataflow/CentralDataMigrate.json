{
	"name": "CentralDataMigrate",
	"properties": {
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "CentralSource",
						"type": "DatasetReference"
					},
					"name": "ReadSource"
				},
				{
					"dataset": {
						"referenceName": "DatavalidationSegment",
						"type": "DatasetReference"
					},
					"name": "ReadSegmentAllowed"
				},
				{
					"dataset": {
						"referenceName": "DatavalidationShipMode",
						"type": "DatasetReference"
					},
					"name": "ReadShipModeAllowed"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "SalesSQL",
						"type": "DatasetReference"
					},
					"name": "InsertinSQL",
					"rejectedDataLinkedService": {
						"referenceName": "AzureBlobStorage1",
						"type": "LinkedServiceReference"
					}
				},
				{
					"dataset": {
						"referenceName": "DumpRowstobeFixed",
						"type": "DatasetReference"
					},
					"name": "InsertinCSV"
				},
				{
					"dataset": {
						"referenceName": "SalesLogsSQL",
						"type": "DatasetReference"
					},
					"name": "AddLogs1"
				}
			],
			"transformations": [
				{
					"name": "RemoveDuplicates"
				},
				{
					"name": "RowswithNulls"
				},
				{
					"name": "AddColumns"
				},
				{
					"name": "SourceRowCount"
				},
				{
					"name": "ErrorRowCount"
				},
				{
					"name": "DuplicateRowCount"
				},
				{
					"name": "RenameColumns"
				},
				{
					"name": "AddDuplicateRows"
				},
				{
					"name": "AddErrorRows"
				},
				{
					"name": "MergeSegment"
				},
				{
					"name": "MergeShipMode"
				},
				{
					"name": "FixNullValues"
				}
			],
			"scriptLines": [
				"source(output(",
				"          {Order ID} as string,",
				"          {Order Date} as string,",
				"          {Ship Date} as string,",
				"          {Ship Mode} as string,",
				"          {Customer ID} as string,",
				"          Segment as string,",
				"          {Postal Code} as string,",
				"          {Product ID} as string,",
				"          Sales as string,",
				"          Quantity as string,",
				"          Discount as string,",
				"          Profit as string",
				"     ),",
				"     allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     ignoreNoFilesFound: false,",
				"     rowUrlColumn: 'Source_File',",
				"     wildcardPaths:['*.xlsx'],",
				"     mode: 'read') ~> ReadSource",
				"source(output(",
				"          {Segment Allowed} as string",
				"     ),",
				"     allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     ignoreNoFilesFound: false) ~> ReadSegmentAllowed",
				"source(output(",
				"          {Ship Mode Allowed} as string",
				"     ),",
				"     allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     ignoreNoFilesFound: false) ~> ReadShipModeAllowed",
				"RowswithNulls@Retain aggregate(groupBy({Order ID},",
				"          {Ship Mode Allowed},",
				"          {Customer ID},",
				"          {Segment Allowed},",
				"          {Product ID},",
				"          Source_File,",
				"          TimeStamp,",
				"          {Order Date Converted},",
				"          {Ship Date Converted},",
				"          {Postal Code Converted},",
				"          {Sales Converted},",
				"          {Quantity Converted},",
				"          {Discount Converted},",
				"          {Profit Converted}),",
				"     Dummy = sum(1)) ~> RemoveDuplicates",
				"AddColumns split(!isNull({Order ID}) && !isNull({Order Date Converted}) && !isNull({Ship Date Converted}) && !isNull({Ship Mode Allowed}) && !isNull({Customer ID}) && !isNull({Segment Allowed}) && !isNull({Postal Code Converted}) && !isNull({Product ID}) && !isNull({Sales Converted}) && !isNull({Quantity Converted}) && !isNull({Discount Converted}) && !isNull({Profit Converted}),",
				"     disjoint: false) ~> RowswithNulls@(Retain, Ignore)",
				"MergeShipMode derive(TimeStamp = currentUTC(),",
				"          {Order Date Converted} = toDate({Order Date},'yyyy-MM-dd'),",
				"          {Ship Date Converted} = toDate({Ship Date},'yyyy-MM-dd'),",
				"          {Postal Code Converted} = toInteger({Postal Code}),",
				"          {Sales Converted} = toDouble(Sales),",
				"          {Quantity Converted} = toInteger(Quantity),",
				"          {Discount Converted} = round(toFloat(Discount),2),",
				"          {Profit Converted} = round(toFloat(Profit),2)) ~> AddColumns",
				"AddColumns aggregate(groupBy(Source_File,",
				"          TimeStamp),",
				"     RowCount = sum(1)) ~> SourceRowCount",
				"RowswithNulls@Ignore aggregate(groupBy(Source_File,",
				"          TimeStamp),",
				"     ErrorRowCount = sum(1)) ~> ErrorRowCount",
				"RemoveDuplicates aggregate(groupBy(Source_File,",
				"          TimeStamp),",
				"     DuplicateRowCount = sum(iif(Dummy != 1, Dummy - 1, toLong(0)))) ~> DuplicateRowCount",
				"ReadSource select(mapColumn(",
				"          {Order ID},",
				"          {Order Date},",
				"          {Ship Date},",
				"          {Ship Mode},",
				"          {Customer ID},",
				"          Segment,",
				"          {Postal Code},",
				"          {Product ID},",
				"          Sales,",
				"          Quantity,",
				"          Discount,",
				"          Profit,",
				"          Source_File",
				"     ),",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true) ~> RenameColumns",
				"SourceRowCount, DuplicateRowCount join(SourceRowCount@Source_File == DuplicateRowCount@Source_File,",
				"     joinType:'left',",
				"     matchType:'exact',",
				"     ignoreSpaces: false,",
				"     broadcast: 'auto')~> AddDuplicateRows",
				"AddDuplicateRows, ErrorRowCount join(SourceRowCount@Source_File == ErrorRowCount@Source_File,",
				"     joinType:'left',",
				"     matchType:'exact',",
				"     ignoreSpaces: false,",
				"     broadcast: 'auto')~> AddErrorRows",
				"RenameColumns, ReadSegmentAllowed join(fuzzyCompare(Segment, {Segment Allowed}, 85.00),",
				"     joinType:'left',",
				"     matchType:'fuzzy',",
				"     ignoreSpaces: true,",
				"     broadcast: 'off')~> MergeSegment",
				"MergeSegment, ReadShipModeAllowed join(fuzzyCompare({Ship Mode}, {Ship Mode Allowed}, 85.00),",
				"     joinType:'left',",
				"     matchType:'fuzzy',",
				"     ignoreSpaces: true,",
				"     broadcast: 'off')~> MergeShipMode",
				"AddErrorRows derive(DuplicateRowCount = iif(isNull(DuplicateRowCount),0,toInteger(DuplicateRowCount)),",
				"          ErrorRowCount = iif(isNull(ErrorRowCount),0,toInteger(ErrorRowCount))) ~> FixNullValues",
				"RemoveDuplicates sink(allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     input(",
				"          Order_ID as string,",
				"          Order_Date as date,",
				"          Ship_Date as date,",
				"          Ship_Mode as string,",
				"          Customer_ID as string,",
				"          Segment as string,",
				"          Postal_Code as integer,",
				"          Product_ID as string,",
				"          SALES as decimal(20,2),",
				"          QUANTITY as integer,",
				"          Discount as double,",
				"          Profit as double,",
				"          Create_Timestamp as timestamp,",
				"          SOURCE_FILE as string",
				"     ),",
				"     deletable:false,",
				"     insertable:true,",
				"     updateable:false,",
				"     upsertable:false,",
				"     format: 'table',",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     errorHandlingOption: 'allErrors',",
				"     outputRejectedData: true,",
				"     rejectedData_container: 'tes-rawdata',",
				"     rejectedData_folderPath: 'Rows_to_be_Fixed',",
				"     transactionCommit: 'single',",
				"     reportSuccessOnError: false,",
				"     mapColumn(",
				"          Order_ID = {Order ID},",
				"          Order_Date = {Order Date Converted},",
				"          Ship_Date = {Ship Date Converted},",
				"          Ship_Mode = {Ship Mode Allowed},",
				"          Customer_ID = {Customer ID},",
				"          Segment = {Segment Allowed},",
				"          Postal_Code = {Postal Code Converted},",
				"          Product_ID = {Product ID},",
				"          SALES = {Sales Converted},",
				"          QUANTITY = {Quantity Converted},",
				"          Discount = {Discount Converted},",
				"          Profit = {Profit Converted},",
				"          Create_Timestamp = TimeStamp,",
				"          SOURCE_FILE = Source_File",
				"     )) ~> InsertinSQL",
				"RowswithNulls@Ignore sink(allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     input(",
				"          Column_1 as string,",
				"          Column_2 as string,",
				"          Column_3 as string,",
				"          Column_4 as string,",
				"          Column_5 as string,",
				"          Column_6 as string,",
				"          Column_7 as string,",
				"          Column_8 as string,",
				"          Column_9 as string,",
				"          Column_10 as string,",
				"          Column_11 as string,",
				"          Column_12 as string",
				"     ),",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true) ~> InsertinCSV",
				"FixNullValues sink(allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     input(",
				"          SOURCE_FILE as string,",
				"          TIMESTAMP as timestamp,",
				"          SOURCE_ROW_COUNT as integer,",
				"          ERROR_ROWS as integer,",
				"          DUPLICATE_ROW_COUNT as integer,",
				"          FINAL_COUNT as integer",
				"     ),",
				"     deletable:false,",
				"     insertable:true,",
				"     updateable:false,",
				"     upsertable:false,",
				"     format: 'table',",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     errorHandlingOption: 'stopOnFirstError',",
				"     mapColumn(",
				"          SOURCE_FILE = SourceRowCount@Source_File,",
				"          TIMESTAMP = SourceRowCount@TimeStamp,",
				"          SOURCE_ROW_COUNT = RowCount,",
				"          DUPLICATE_ROW_COUNT = DuplicateRowCount,",
				"          ERROR_ROWS = ErrorRowCount",
				"     )) ~> AddLogs1"
			]
		}
	}
}