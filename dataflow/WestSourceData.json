{
	"name": "WestSourceData",
	"properties": {
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "WestSource",
						"type": "DatasetReference"
					},
					"name": "ReadSource"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "SalesSQL",
						"type": "DatasetReference"
					},
					"name": "InsertinSQL"
				},
				{
					"dataset": {
						"referenceName": "DumpRowstobeFixed",
						"type": "DatasetReference"
					},
					"name": "InsertinCSV"
				},
				{
					"dataset": {
						"referenceName": "SalesLogsSQL",
						"type": "DatasetReference"
					},
					"name": "AddLogs1"
				},
				{
					"dataset": {
						"referenceName": "SalesLogsSQL",
						"type": "DatasetReference"
					},
					"name": "AddLogs2"
				},
				{
					"dataset": {
						"referenceName": "SalesLogsSQL",
						"type": "DatasetReference"
					},
					"name": "AddLogs3"
				}
			],
			"transformations": [
				{
					"name": "RemoveDuplicates"
				},
				{
					"name": "RowswithNulls"
				},
				{
					"name": "AddCreateTimeStamp"
				},
				{
					"name": "SourceRowCount"
				},
				{
					"name": "ChangeType1"
				},
				{
					"name": "ErrorRowCount"
				},
				{
					"name": "DuplicateRowCount"
				},
				{
					"name": "ChangeType2"
				},
				{
					"name": "ChangeType3"
				},
				{
					"name": "RenameColumns"
				}
			],
			"scriptLines": [
				"source(output(",
				"          {_col0_} as string,",
				"          {_col1_} as string,",
				"          {_col2_} as string,",
				"          {_col3_} as string,",
				"          {_col4_} as string,",
				"          {_col5_} as string,",
				"          {_col6_} as string,",
				"          {_col7_} as string,",
				"          {_col8_} as string,",
				"          {_col9_} as string,",
				"          {_col10_} as string,",
				"          {_col11_} as string",
				"     ),",
				"     allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     ignoreNoFilesFound: false,",
				"     enableCdc: true,",
				"     mode: 'read',",
				"     skipInitialLoad: false,",
				"     rowUrlColumn: 'Source_File') ~> ReadSource",
				"RowswithNulls@Retain aggregate(groupBy({Order ID},",
				"          {Order Date},",
				"          {Ship Date},",
				"          {Ship Mode},",
				"          {Customer ID},",
				"          Segment,",
				"          {Postal Code},",
				"          {Product ID},",
				"          Sales,",
				"          Quantity,",
				"          Discount,",
				"          Profit,",
				"          Source_File,",
				"          TimeStamp),",
				"     Dummy = sum(1)) ~> RemoveDuplicates",
				"AddCreateTimeStamp split(!isNull({Order ID}) && !isNull({Order Date}) && !isNull({Ship Date}) && !isNull({Ship Mode}) && !isNull({Customer ID}) && !isNull(Segment) && !isNull({Postal Code}) && !isNull({Product ID}) && !isNull(Sales) && !isNull(Quantity) && !isNull(Discount) && !isNull(Profit),",
				"     disjoint: false) ~> RowswithNulls@(Retain, Ignore)",
				"RenameColumns derive(TimeStamp = currentUTC()) ~> AddCreateTimeStamp",
				"AddCreateTimeStamp aggregate(groupBy(Source_File,",
				"          TimeStamp),",
				"     RowCount = sum(1)) ~> SourceRowCount",
				"SourceRowCount alterRow(upsertIf(true())) ~> ChangeType1",
				"RowswithNulls@Ignore aggregate(groupBy(Source_File,",
				"          TimeStamp),",
				"     RowCount = sum(1)) ~> ErrorRowCount",
				"RemoveDuplicates aggregate(groupBy(Source_File,",
				"          TimeStamp),",
				"     RowCount = sum(iif(Dummy != 1, Dummy - 1, toLong(0)))) ~> DuplicateRowCount",
				"DuplicateRowCount alterRow(upsertIf(true())) ~> ChangeType2",
				"ErrorRowCount alterRow(upsertIf(true())) ~> ChangeType3",
				"ReadSource select(mapColumn(",
				"          {Order ID} = {_col0_},",
				"          {Order Date} = {_col1_},",
				"          {Ship Date} = {_col2_},",
				"          {Ship Mode} = {_col3_},",
				"          {Customer ID} = {_col4_},",
				"          Segment = {_col5_},",
				"          {Postal Code} = {_col6_},",
				"          {Product ID} = {_col7_},",
				"          Sales = {_col8_},",
				"          Quantity = {_col9_},",
				"          Discount = {_col10_},",
				"          Profit = {_col11_},",
				"          Source_File",
				"     ),",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true) ~> RenameColumns",
				"RemoveDuplicates sink(allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     input(",
				"          Order_ID as string,",
				"          Order_Date as date,",
				"          Ship_Date as date,",
				"          Ship_Mode as string,",
				"          Customer_ID as string,",
				"          Segment as string,",
				"          Postal_Code as integer,",
				"          Product_ID as string,",
				"          SALES as decimal(20,2),",
				"          QUANTITY as integer,",
				"          Discount as double,",
				"          Profit as double,",
				"          Create_Timestamp as timestamp,",
				"          SOURCE_FILE as string",
				"     ),",
				"     deletable:false,",
				"     insertable:true,",
				"     updateable:false,",
				"     upsertable:false,",
				"     format: 'table',",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     errorHandlingOption: 'stopOnFirstError',",
				"     mapColumn(",
				"          Order_ID = {Order ID},",
				"          Order_Date = {Order Date},",
				"          Ship_Date = {Ship Date},",
				"          Ship_Mode = {Ship Mode},",
				"          Customer_ID = {Customer ID},",
				"          Segment,",
				"          Postal_Code = {Postal Code},",
				"          Product_ID = {Product ID},",
				"          SALES = Sales,",
				"          QUANTITY = Quantity,",
				"          Discount,",
				"          Profit,",
				"          Create_Timestamp = TimeStamp,",
				"          SOURCE_FILE = Source_File",
				"     )) ~> InsertinSQL",
				"RowswithNulls@Ignore sink(allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     input(",
				"          Column_1 as string,",
				"          Column_2 as string,",
				"          Column_3 as string,",
				"          Column_4 as string,",
				"          Column_5 as string,",
				"          Column_6 as string,",
				"          Column_7 as string,",
				"          Column_8 as string,",
				"          Column_9 as string,",
				"          Column_10 as string,",
				"          Column_11 as string,",
				"          Column_12 as string",
				"     ),",
				"     partitionFileNames:['Rows_to_be_fixed.csv'],",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     mapColumn(",
				"          {Order ID},",
				"          {Order Date},",
				"          {Ship Date},",
				"          {Ship Mode},",
				"          {Customer ID},",
				"          Segment,",
				"          {Postal Code},",
				"          {Product ID},",
				"          Sales,",
				"          Quantity,",
				"          Discount,",
				"          Profit,",
				"          Source_File",
				"     ),",
				"     partitionBy('hash', 1)) ~> InsertinCSV",
				"ChangeType1 sink(allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     input(",
				"          SOURCE_FILE as string,",
				"          TIMESTAMP as timestamp,",
				"          SOURCE_ROW_COUNT as integer,",
				"          ERROR_ROWS as integer,",
				"          DUPLICATE_ROW_COUNT as integer,",
				"          FINAL_COUNT as integer",
				"     ),",
				"     deletable:false,",
				"     insertable:false,",
				"     updateable:false,",
				"     upsertable:true,",
				"     keys:['SOURCE_FILE','TIMESTAMP'],",
				"     format: 'table',",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     errorHandlingOption: 'stopOnFirstError',",
				"     mapColumn(",
				"          SOURCE_FILE = Source_File,",
				"          TIMESTAMP = TimeStamp,",
				"          SOURCE_ROW_COUNT = RowCount",
				"     )) ~> AddLogs1",
				"ChangeType2 sink(allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     input(",
				"          SOURCE_FILE as string,",
				"          TIMESTAMP as timestamp,",
				"          SOURCE_ROW_COUNT as integer,",
				"          ERROR_ROWS as integer,",
				"          DUPLICATE_ROW_COUNT as integer,",
				"          FINAL_COUNT as integer",
				"     ),",
				"     deletable:false,",
				"     insertable:false,",
				"     updateable:false,",
				"     upsertable:true,",
				"     keys:['SOURCE_FILE','TIMESTAMP'],",
				"     format: 'table',",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     errorHandlingOption: 'stopOnFirstError',",
				"     mapColumn(",
				"          SOURCE_FILE = Source_File,",
				"          TIMESTAMP = TimeStamp,",
				"          DUPLICATE_ROW_COUNT = RowCount",
				"     )) ~> AddLogs2",
				"ChangeType3 sink(allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     input(",
				"          SOURCE_FILE as string,",
				"          TIMESTAMP as timestamp,",
				"          SOURCE_ROW_COUNT as integer,",
				"          ERROR_ROWS as integer,",
				"          DUPLICATE_ROW_COUNT as integer,",
				"          FINAL_COUNT as integer",
				"     ),",
				"     deletable:false,",
				"     insertable:false,",
				"     updateable:false,",
				"     upsertable:true,",
				"     keys:['SOURCE_FILE','TIMESTAMP'],",
				"     format: 'table',",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     errorHandlingOption: 'stopOnFirstError',",
				"     mapColumn(",
				"          SOURCE_FILE = Source_File,",
				"          TIMESTAMP = TimeStamp,",
				"          ERROR_ROWS = RowCount",
				"     )) ~> AddLogs3"
			]
		}
	}
}