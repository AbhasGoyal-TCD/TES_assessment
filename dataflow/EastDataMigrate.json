{
	"name": "EastDataMigrate",
	"properties": {
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "EastSource",
						"type": "DatasetReference"
					},
					"name": "ReadSource"
				},
				{
					"dataset": {
						"referenceName": "DatavalidationSegment",
						"type": "DatasetReference"
					},
					"name": "ReadSegmentAllowed"
				},
				{
					"dataset": {
						"referenceName": "DatavalidationShipMode",
						"type": "DatasetReference"
					},
					"name": "ReadShipModeAllowed"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "SalesSQL",
						"type": "DatasetReference"
					},
					"name": "InsertinSQL",
					"rejectedDataLinkedService": {
						"referenceName": "AzureBlobStorage1",
						"type": "LinkedServiceReference"
					}
				},
				{
					"dataset": {
						"referenceName": "DumpRowstobeFixed",
						"type": "DatasetReference"
					},
					"name": "InsertinCSV"
				},
				{
					"dataset": {
						"referenceName": "SalesLogsSQL",
						"type": "DatasetReference"
					},
					"name": "AddLogs"
				}
			],
			"transformations": [
				{
					"name": "RemoveDuplicates"
				},
				{
					"name": "RowswithNulls"
				},
				{
					"name": "AddColumns"
				},
				{
					"name": "SourceRowCount"
				},
				{
					"name": "ErrorRowCount"
				},
				{
					"name": "DuplicateRowCount"
				},
				{
					"name": "RenameColumns"
				},
				{
					"name": "AddDuplicateRows"
				},
				{
					"name": "AddErrorRoes"
				},
				{
					"name": "MergeSegment"
				},
				{
					"name": "MergeShipMode"
				}
			],
			"scriptLines": [
				"source(output(",
				"          order_number as string,",
				"          ord_date as string,",
				"          ship_date as string,",
				"          ship_type as string,",
				"          customer_key as string,",
				"          customer_section as string,",
				"          post_code as string,",
				"          product_id as string,",
				"          sales as string,",
				"          {#_items} as string,",
				"          reduction as string,",
				"          total as string",
				"     ),",
				"     allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     ignoreNoFilesFound: false,",
				"     rowUrlColumn: 'Source_File',",
				"     mode: 'read') ~> ReadSource",
				"source(output(",
				"          {Segment Allowed} as string",
				"     ),",
				"     allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     ignoreNoFilesFound: false) ~> ReadSegmentAllowed",
				"source(output(",
				"          {Ship Mode Allowed} as string",
				"     ),",
				"     allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     ignoreNoFilesFound: false) ~> ReadShipModeAllowed",
				"RowswithNulls@Retain aggregate(groupBy({Order ID},",
				"          {Ship Mode Allowed},",
				"          {Customer ID},",
				"          {Segment Allowed},",
				"          {Product ID},",
				"          Source_File,",
				"          TimeStamp,",
				"          {Order Date Converted},",
				"          {Ship Date Converted},",
				"          {Postal Code Converted},",
				"          {Sales Converted},",
				"          {Quantity Converted},",
				"          {Discount Converted},",
				"          {Profit Converted}),",
				"     Dummy = sum(1)) ~> RemoveDuplicates",
				"AddColumns split(!isNull({Order ID}) && !isNull({Order Date Converted}) && !isNull({Ship Date Converted}) && !isNull({Ship Mode Allowed}) && !isNull({Customer ID}) && !isNull({Segment Allowed}) && !isNull({Postal Code Converted}) && !isNull({Postal Code}) && !isNull({Sales Converted}) && !isNull({Quantity Converted}) && !isNull({Discount Converted}) && !isNull({Profit Converted}),",
				"     disjoint: false) ~> RowswithNulls@(Retain, Ignore)",
				"MergeShipMode derive(TimeStamp = currentUTC(),",
				"          {Order Date Converted} = toDate(replace({Order Date},'31/11','30/11'),'dd/MM/yyyy'),",
				"          {Ship Date Converted} = toDate(iif(length({Ship Date}) == 9, replace({Ship Date},'202','/202'), replace({Ship Date},'31/06','30/06')),'dd/MM/yyyy'),",
				"          {Postal Code Converted} = toInteger({Postal Code}),",
				"          {Sales Converted} = toDouble(regexReplace(Sales,'[^.0-9]','')),",
				"          {Quantity Converted} = toInteger(regexReplace(Quantity,'[^.0-9]','')),",
				"          {Discount Converted} = round(toFloat(Discount),2),",
				"          {Profit Converted} = round(toFloat(Profit),2),",
				"          {Product ID} = replace({Product ID}, '*', '')) ~> AddColumns",
				"AddColumns aggregate(groupBy(Source_File,",
				"          TimeStamp),",
				"     RowCount = sum(1)) ~> SourceRowCount",
				"RowswithNulls@Ignore aggregate(groupBy(Source_File,",
				"          TimeStamp),",
				"     ErrorRowCount = sum(1)) ~> ErrorRowCount",
				"RemoveDuplicates aggregate(groupBy(Source_File,",
				"          TimeStamp),",
				"     DuplicateRowCount = sum(iif(Dummy != 1, Dummy - 1, toLong(0)))) ~> DuplicateRowCount",
				"ReadSource select(mapColumn(",
				"          {Order ID} = order_number,",
				"          {Order Date} = ord_date,",
				"          {Ship Date} = ship_date,",
				"          {Ship Mode} = ship_type,",
				"          {Customer ID} = customer_key,",
				"          Segment = customer_section,",
				"          {Postal Code} = post_code,",
				"          {Product ID} = product_id,",
				"          Sales = sales,",
				"          Quantity = {#_items},",
				"          Discount = reduction,",
				"          Profit = total,",
				"          Source_File",
				"     ),",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true) ~> RenameColumns",
				"SourceRowCount, DuplicateRowCount join(SourceRowCount@Source_File == DuplicateRowCount@Source_File,",
				"     joinType:'left',",
				"     matchType:'exact',",
				"     ignoreSpaces: false,",
				"     broadcast: 'auto')~> AddDuplicateRows",
				"AddDuplicateRows, ErrorRowCount join(SourceRowCount@Source_File == ErrorRowCount@Source_File,",
				"     joinType:'left',",
				"     matchType:'exact',",
				"     ignoreSpaces: false,",
				"     broadcast: 'auto')~> AddErrorRoes",
				"RenameColumns, ReadSegmentAllowed join(fuzzyCompare(Segment, {Segment Allowed}, 85.00),",
				"     joinType:'left',",
				"     matchType:'fuzzy',",
				"     ignoreSpaces: true,",
				"     broadcast: 'off')~> MergeSegment",
				"MergeSegment, ReadShipModeAllowed join(fuzzyCompare({Ship Mode}, {Ship Mode Allowed}, 85.00),",
				"     joinType:'left',",
				"     matchType:'fuzzy',",
				"     ignoreSpaces: true,",
				"     broadcast: 'auto')~> MergeShipMode",
				"RemoveDuplicates sink(allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     input(",
				"          Order_ID as string,",
				"          Order_Date as date,",
				"          Ship_Date as date,",
				"          Ship_Mode as string,",
				"          Customer_ID as string,",
				"          Segment as string,",
				"          Postal_Code as integer,",
				"          Product_ID as string,",
				"          SALES as decimal(20,2),",
				"          QUANTITY as integer,",
				"          Discount as double,",
				"          Profit as double,",
				"          Create_Timestamp as timestamp,",
				"          SOURCE_FILE as string",
				"     ),",
				"     deletable:false,",
				"     insertable:true,",
				"     updateable:false,",
				"     upsertable:false,",
				"     format: 'table',",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     errorHandlingOption: 'allErrors',",
				"     outputRejectedData: true,",
				"     rejectedData_container: 'tes-rawdata',",
				"     rejectedData_folderPath: 'Rows_to_be_Fixed',",
				"     transactionCommit: 'single',",
				"     reportSuccessOnError: true,",
				"     mapColumn(",
				"          Order_ID = {Order ID},",
				"          Order_Date = {Order Date Converted},",
				"          Ship_Date = {Ship Date Converted},",
				"          Ship_Mode = {Ship Mode Allowed},",
				"          Customer_ID = {Customer ID},",
				"          Segment = {Segment Allowed},",
				"          Postal_Code = {Postal Code Converted},",
				"          Product_ID = {Product ID},",
				"          SALES = {Sales Converted},",
				"          QUANTITY = {Quantity Converted},",
				"          Discount = {Discount Converted},",
				"          Profit = {Profit Converted},",
				"          Create_Timestamp = TimeStamp,",
				"          SOURCE_FILE = Source_File",
				"     )) ~> InsertinSQL",
				"RowswithNulls@Ignore sink(allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     input(",
				"          Column_1 as string,",
				"          Column_2 as string,",
				"          Column_3 as string,",
				"          Column_4 as string,",
				"          Column_5 as string,",
				"          Column_6 as string,",
				"          Column_7 as string,",
				"          Column_8 as string,",
				"          Column_9 as string,",
				"          Column_10 as string,",
				"          Column_11 as string,",
				"          Column_12 as string",
				"     ),",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true) ~> InsertinCSV",
				"AddErrorRoes sink(allowSchemaDrift: false,",
				"     validateSchema: true,",
				"     input(",
				"          SOURCE_FILE as string,",
				"          TIMESTAMP as timestamp,",
				"          SOURCE_ROW_COUNT as integer,",
				"          ERROR_ROWS as integer,",
				"          DUPLICATE_ROW_COUNT as integer,",
				"          FINAL_COUNT as integer",
				"     ),",
				"     deletable:false,",
				"     insertable:true,",
				"     updateable:false,",
				"     upsertable:false,",
				"     format: 'table',",
				"     skipDuplicateMapInputs: true,",
				"     skipDuplicateMapOutputs: true,",
				"     errorHandlingOption: 'stopOnFirstError',",
				"     mapColumn(",
				"          SOURCE_FILE = SourceRowCount@Source_File,",
				"          TIMESTAMP = SourceRowCount@TimeStamp,",
				"          SOURCE_ROW_COUNT = RowCount,",
				"          ERROR_ROWS = DuplicateRowCount,",
				"          DUPLICATE_ROW_COUNT = ErrorRowCount",
				"     )) ~> AddLogs"
			]
		}
	}
}