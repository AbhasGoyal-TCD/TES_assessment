{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "Agoyal-factory"
		},
		"AzureBlobStorage1_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'AzureBlobStorage1'"
		},
		"AzureSqlDatabase1_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'AzureSqlDatabase1'"
		},
		"AzureTableStorage1_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'AzureTableStorage1'"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/CreateDB')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "CreateCompanies",
						"type": "Script",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase1",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "NonQuery",
									"text": "IF  EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[Companies]') AND type in (N'U'))\r\nDROP TABLE [dbo].[Companies]\r\n\r\n\r\nCREATE TABLE Companies(\r\n    Company_ID INTEGER PRIMARY KEY,\r\n    Company NVARCHAR(255),\r\n    Contact NVARCHAR(255),\r\n    Region NVARCHAR(255),\r\n);"
								}
							]
						}
					},
					{
						"name": "CreatePostalCode",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "CheckandDeleteMergedData",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase1",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "NonQuery",
									"text": "IF  EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[Postal_Code]') AND type in (N'U'))\r\nDROP TABLE [dbo].[Postal_Code]\r\n\r\n\r\nCREATE TABLE Postal_Code(\r\n    Postal_Code INTEGER PRIMARY KEY,\r\n    State NVARCHAR(255),\r\n    Region NVARCHAR(255),\r\n    Country_Region NVARCHAR(255),\r\n    Country NVARCHAR(255)\r\n);"
								}
							]
						}
					},
					{
						"name": "CreateProductType",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "CheckandDeleteProducts",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase1",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "NonQuery",
									"text": "IF  EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[Product_Types]') AND type in (N'U'))\r\nDROP TABLE [dbo].[Product_Types]\r\n\r\n\r\nCREATE TABLE Product_Types(\r\n    Product_Type NVARCHAR(255) PRIMARY KEY,\r\n    Product_Category NVARCHAR(255)\r\n);"
								}
							]
						}
					},
					{
						"name": "CreateProducts",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "CreateProductType",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase1",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "NonQuery",
									"text": "CREATE TABLE Products(\r\n    Product_ID NVARCHAR(255) PRIMARY KEY,\r\n    Product_Name NVARCHAR(255),\r\n    Category NVARCHAR(255),\r\n    FOREIGN KEY (Category) REFERENCES Product_Types(Product_Type)\r\n);"
								}
							]
						}
					},
					{
						"name": "CreateMergedData",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "CreatePostalCode",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "CreateProducts",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase1",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "NonQuery",
									"text": "CREATE TABLE MERGED_DATA(\r\n    Order_ID NVARCHAR(255),\r\n    Order_Date DATE,\r\n    Ship_Date DATE,\r\n    Ship_Mode NVARCHAR(255),\r\n    Customer_ID NVARCHAR(255),\r\n    Segment NVARCHAR(255),\r\n    Postal_Code INTEGER,\r\n    Product_ID NVARCHAR(255),\r\n    SALES decimal(20,2),\r\n    QUANTITY INTEGER,\r\n    Discount FLOAT,\r\n    Profit FLOAT,\r\n    Create_Timestamp DATETIME,\r\n    SOURCE_FILE NVARCHAR(255),\r\n    FOREIGN KEY (Postal_Code) REFERENCES Postal_Code(Postal_Code),\r\n    FOREIGN KEY (Product_ID) REFERENCES Products(Product_ID)\r\n);"
								}
							]
						}
					},
					{
						"name": "CreateMergedDataLogs",
						"type": "Script",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase1",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "NonQuery",
									"text": "IF  EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[MERGED_DATA_LOGS]') AND type in (N'U'))\r\nDROP TABLE [dbo].[MERGED_DATA_LOGS]\r\n\r\n\r\nCREATE TABLE MERGED_DATA_LOGS(\r\n    SOURCE_FILE NVARCHAR(255),\r\n    TIMESTAMP DATETIME,\r\n    SOURCE_ROW_COUNT INTEGER,\r\n    ERROR_ROWS INTEGER,\r\n    DUPLICATE_ROW_COUNT INTEGER,\r\n    FINAL_COUNT INTEGER\r\n);"
								}
							]
						}
					},
					{
						"name": "CheckandDeleteMergedData",
						"type": "Script",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase1",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "NonQuery",
									"text": "IF  EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[MERGED_DATA]') AND type in (N'U'))\nDROP TABLE [dbo].[MERGED_DATA]"
								}
							]
						}
					},
					{
						"name": "CheckandDeleteProducts",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "CheckandDeleteMergedData",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase1",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "NonQuery",
									"text": "IF  EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[Products]') AND type in (N'U'))\nDROP TABLE [dbo].[Products]"
								}
							]
						}
					},
					{
						"name": "CreateMetaDataLogs",
						"type": "Script",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase1",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "NonQuery",
									"text": "IF  EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[dbo].[META_DATA_LOGS]') AND type in (N'U'))\r\nDROP TABLE [dbo].[META_DATA_LOGS]\r\n\r\n\r\nCREATE TABLE META_DATA_LOGS(\r\n    SOURCE_FILE NVARCHAR(255),\r\n    SOURCE_ROW_COUNT INTEGER,\r\n    ERROR_ROWS INTEGER,\r\n    DUPLICATE_ROW_COUNT INTEGER,\r\n    IGNORE_ROW_COUNT INTEGER,\r\n    FINAL_COUNT INTEGER\r\n);"
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/RemoveLatestData')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "ChecktoDeleteCentral",
						"type": "IfCondition",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(pipeline().parameters.RemoveCentralData, bool(1) )",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "DeleteCentralLatest",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "DeleteCentralLog",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "delete from MERGED_DATA\nwhere SOURCE_FILE like '/Central_Data/%' and  Create_Timestamp = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/Central_Data/%')"
											}
										]
									}
								},
								{
									"name": "DeleteCentralLog",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "delete from MERGED_DATA_LOGS\nwhere SOURCE_FILE like '/Central_Data/%' and  TIMESTAMP = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/Central_Data/%')"
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "ChecktoDeleteEast",
						"type": "IfCondition",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(pipeline().parameters.RemoveEastData, bool(1) )",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "DeleteEastLatest",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "DeleteEastLog",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "delete from MERGED_DATA\nwhere SOURCE_FILE like '/East_Data/%' and  Create_Timestamp = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/East_Data/%')"
											}
										]
									}
								},
								{
									"name": "DeleteEastLog",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "delete from MERGED_DATA_LOGS\r\nwhere SOURCE_FILE like '/East_Data/%' and  TIMESTAMP = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/East_Data/%')"
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "ChecktoDeleteWest",
						"type": "IfCondition",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(pipeline().parameters.RemoveWestData, bool(1) )",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "DeleteWestLatest",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "DeleteWestLog",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "delete from MERGED_DATA\nwhere SOURCE_FILE like '/West_Data/%' and  Create_Timestamp = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/West_Data/%')"
											}
										]
									}
								},
								{
									"name": "DeleteWestLog",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "delete from MERGED_DATA_LOGS\r\nwhere SOURCE_FILE like '/West_Data/%' and  TIMESTAMP = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/West_Data/%')"
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "ChecktoDeleteSouth",
						"type": "IfCondition",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(pipeline().parameters.RemoveSouthData, bool(1) )",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "DeleteSouthLatest",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "DeleteSouthLog",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "delete from MERGED_DATA\nwhere SOURCE_FILE like '/West_Data/%' and  Create_Timestamp = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/West_Data/%')"
											}
										]
									}
								},
								{
									"name": "DeleteSouthLog",
									"type": "Script",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "delete from MERGED_DATA_LOGS\r\nwhere SOURCE_FILE like '/South_Data/%' and  TIMESTAMP = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/South_Data/%')"
											}
										]
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"parameters": {
					"RemoveCentralData": {
						"type": "bool",
						"defaultValue": false
					},
					"RemoveEastData": {
						"type": "bool",
						"defaultValue": false
					},
					"RemoveSouthData": {
						"type": "bool",
						"defaultValue": false
					},
					"RemoveWestData": {
						"type": "bool",
						"defaultValue": true
					}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/UploadCentralSalesData')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "LoadCentralSourceCount",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "ExcelSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"wildcardFileName": "*.xlsx",
									"enablePartitionDiscovery": false
								}
							},
							"dataset": {
								"referenceName": "CentralSource",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "VerifyCentralSourceCount",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "LoadCentralSourceCount",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(activity('LoadCentralSourceCount').output.count,41) \n",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "UploadCentralSource",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "1.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "CentralDataMigrate",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"ReadSource": {},
												"ReadSegmentAllowed": {},
												"ReadShipModeAllowed": {},
												"InsertinSQL": {},
												"InsertinCSV": {},
												"AddLogs1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								},
								{
									"name": "UpdateFinalCountCentral",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "UploadCentralSource",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "Update MERGED_DATA_LOGS\nSet FINAL_COUNT = (select Count(*) from MERGED_DATA where SOURCE_FILE like '/Central_Data/%' and Create_Timestamp = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/Central_Data/%') )\nwhere SOURCE_FILE like '/Central_Data/%' and  TIMESTAMP = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/Central_Data/%')"
											}
										]
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": [],
				"lastPublishTime": "2022-06-12T12:20:18Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/CentralSource')]",
				"[concat(variables('factoryId'), '/dataflows/CentralDataMigrate')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/UploadEastSalesData')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "LoadEastSourceCount",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"wildcardFileName": "*.csv",
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"dataset": {
								"referenceName": "EastSource",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "VerifyEastSourceCount",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "LoadEastSourceCount",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(activity('LoadEastSourceCount').output.count,41) \n",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "EastDataMigrate",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "1.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "EastDataMigrate",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"ReadSource": {},
												"ReadSegmentAllowed": {},
												"ReadShipModeAllowed": {},
												"InsertinSQL": {},
												"InsertinCSV": {},
												"AddLogs": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								},
								{
									"name": "UpdateFinalCountEast",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "EastDataMigrate",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "Update MERGED_DATA_LOGS\nSet FINAL_COUNT = (select Count(*) from MERGED_DATA where SOURCE_FILE like '/East_Data/%' and Create_Timestamp = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/East_Data/%') )\nwhere SOURCE_FILE like '/East_Data/%' and  TIMESTAMP = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/East_Data/%')"
											}
										]
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": [],
				"lastPublishTime": "2022-06-12T12:20:18Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/EastSource')]",
				"[concat(variables('factoryId'), '/dataflows/EastDataMigrate')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/UploadMetadata')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "VerifyCompaniesCount",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "LoadCompaniesCount",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(activity('LoadCompaniesCount').output.count,4 )",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "CompaniesMetadata",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "1.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "CompaniesMetadata",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"ReadSource": {},
												"ReadSQL": {},
												"InsertinSQL": {},
												"RecordNullRows": {},
												"AddLogs": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								},
								{
									"name": "UpdateFinalCountCompanies",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "CompaniesMetadata",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "Update META_DATA_LOGS\r\nset FINAL_COUNT = (SELECT Count(Company_ID) from Companies)\r\nwhere Source_File = 'Company'"
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "LoadCompaniesCount",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "ExcelSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								}
							},
							"dataset": {
								"referenceName": "CompaniesExcel",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "LoadPostalCodeCount",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "ExcelSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								}
							},
							"dataset": {
								"referenceName": "PostalCodesExcel",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "VerifyPostalCodeCount",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "LoadPostalCodeCount",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(activity('LoadPostalCodeCount').output.count,632 )",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "PostalCodeMetadata",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "1.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "PostalCodeMetadata_v2",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"ReadSource": {},
												"ReadSQL": {},
												"InsertinSQL": {},
												"RecordNullRows": {},
												"AddLogs": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								},
								{
									"name": "UpdateFinalCountPostalCode",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "PostalCodeMetadata",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "Update META_DATA_LOGS\r\nset FINAL_COUNT = (SELECT Count(Postal_Code) from Postal_Code)\r\nwhere Source_File = 'PostalCode'"
											}
										]
									}
								}
							]
						}
					},
					{
						"name": "LoadProductTypesCount",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "ExcelSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								}
							},
							"dataset": {
								"referenceName": "ProductTypesExcel",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "VerifyProductTypesCount",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "LoadProductTypesCount",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(activity('LoadProductTypesCount').output.count,17 )",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "ProductTypesMetadata",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "1.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "ProductTypesMetadata_v2",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"ReadSource": {},
												"ReadSQL": {},
												"InsertinSQL": {},
												"RecordNullRows": {},
												"AddLogs": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								},
								{
									"name": "UpdateFinalCountProductTypes",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "ProductTypesMetadata",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "Update META_DATA_LOGS\r\nset FINAL_COUNT = (SELECT Count(Product_Type) from Product_Types)\r\nwhere Source_File = 'ProductTypes'"
											}
										]
									}
								},
								{
									"name": "Addmissingproducttypes",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "UpdateFinalCountProductTypes",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "INSERT INTO Product_Types\nSelect 'Unknown','Unknown'\nwhere not exists (select 1 from Product_Types where Product_Type = 'Unknown' )"
											}
										]
									}
								},
								{
									"name": "SetFlagforProducts",
									"type": "SetVariable",
									"dependsOn": [
										{
											"activity": "ProductTypesMetadata",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"variableName": "ProductTypeCompletion",
										"value": {
											"value": "@bool(1)",
											"type": "Expression"
										}
									}
								}
							]
						}
					},
					{
						"name": "LoadProductsCount",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "VerifyProductTypesCount",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "ExcelSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								}
							},
							"dataset": {
								"referenceName": "ProductsExcel",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "VerifyProductsCount",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "LoadProductsCount",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@and(equals(activity('LoadProductsCount').output.count,75),equals(variables('ProductTypeCompletion'), bool(1)) )",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "ProductsMetadata_v2",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "1.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "ProductsMetadata_v2",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"ReadSource": {},
												"ReadSQL": {},
												"InsertinSQL": {},
												"RecordNullRows": {},
												"AddLogs": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								},
								{
									"name": "UpdateFinalCountProducts",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "ProductsMetadata_v2",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "Update META_DATA_LOGS\r\nset FINAL_COUNT = (SELECT Count(Product_ID) from Products)\r\nwhere Source_File = 'Products'"
											}
										]
									}
								},
								{
									"name": "Addmissingproducts",
									"description": "INSERT INTO Products \nSelect 'FUR-BO-10001810','','BookCases'\nwhere not exists (select 1 from Products where Product_ID = 'FUR-BO-10001810');\n\nINSERT INTO Products \nSelect 'FUR-TA-10000199','','Tables'\nwhere not exists (select 1 from Products where Product_ID = 'FUR-TA-10000199');\n\nINSERT INTO Products \nSelect 'Product Unknown','','Unknown'\nwhere not exists (select 1 from Products where Product_ID = 'Product Unknown');",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "UpdateFinalCountProducts",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "INSERT INTO Products \nSelect 'FUR-BO-10001810','','BookCases'\nwhere not exists (select 1 from Products where Product_ID = 'FUR-BO-10001810');\n\nINSERT INTO Products \nSelect 'FUR-TA-10000199','','Tables'\nwhere not exists (select 1 from Products where Product_ID = 'FUR-TA-10000199');\n\nINSERT INTO Products \nSelect 'Product Unknown','','Unknown'\nwhere not exists (select 1 from Products where Product_ID = 'Product Unknown');"
											}
										]
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"variables": {
					"ProductTypeCompletion": {
						"type": "Boolean",
						"defaultValue": false
					}
				},
				"annotations": [],
				"lastPublishTime": "2022-06-12T11:39:05Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/CompaniesExcel')]",
				"[concat(variables('factoryId'), '/datasets/PostalCodesExcel')]",
				"[concat(variables('factoryId'), '/datasets/ProductTypesExcel')]",
				"[concat(variables('factoryId'), '/datasets/ProductsExcel')]",
				"[concat(variables('factoryId'), '/dataflows/CompaniesMetadata')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]",
				"[concat(variables('factoryId'), '/dataflows/PostalCodeMetadata_v2')]",
				"[concat(variables('factoryId'), '/dataflows/ProductTypesMetadata_v2')]",
				"[concat(variables('factoryId'), '/dataflows/ProductsMetadata_v2')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/UploadSouthSalesData')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "LoadSouthSourceCount",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "LoadSouthSourceCount",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"Json": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "None",
							"cacheSinks": {
								"firstRowOnly": true
							}
						}
					},
					{
						"name": "VerifySouthSourceCount",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "LoadSouthSourceCount",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(activity('LoadSouthSourceCount').output.runStatus.output.sink1.value[0].RowCount,25)",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "SouthDataMigrate",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "1.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "SouthDataMigrate",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"ReadSource": {},
												"ReadSegmentAllowed": {},
												"ReadShipModeAllowed": {},
												"InsertinSQL": {},
												"InsertinCSV": {},
												"AddLogs": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								},
								{
									"name": "UpdateFinalCountSouth",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "SouthDataMigrate",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "Query",
												"text": "Update MERGED_DATA_LOGS\nSet FINAL_COUNT = (select Count(*) from MERGED_DATA where SOURCE_FILE like '/South_Data/%' and Create_Timestamp = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/South_Data/%') )\nwhere SOURCE_FILE like '/South_Data/%' and  TIMESTAMP = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/South_Data/%')"
											}
										]
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": [],
				"lastPublishTime": "2022-06-12T12:20:18Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/LoadSouthSourceCount')]",
				"[concat(variables('factoryId'), '/dataflows/SouthDataMigrate')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/UploadWestSalesData')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "LoadWestSourceCount",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "ExcelSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"wildcardFileName": "*.xlsx",
									"enablePartitionDiscovery": false
								}
							},
							"dataset": {
								"referenceName": "WestSource",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "VerifyWestSourceCount",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "LoadWestSourceCount",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(activity('LoadWestSourceCount').output.count,48) \n",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "WestSourceData",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "1.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "WestDataMigrate",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"ReadSource": {},
												"ReadSegmentAllowed": {},
												"ReadShipModeAllowed": {},
												"InsertinSQL": {},
												"InsertinCSV": {},
												"AddLogs": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								},
								{
									"name": "UpdateFinalCountWest",
									"type": "Script",
									"dependsOn": [
										{
											"activity": "WestSourceData",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"linkedServiceName": {
										"referenceName": "AzureSqlDatabase1",
										"type": "LinkedServiceReference"
									},
									"typeProperties": {
										"scripts": [
											{
												"type": "NonQuery",
												"text": "Update MERGED_DATA_LOGS\nSet FINAL_COUNT = (select Count(*) from MERGED_DATA where SOURCE_FILE like '/West_Data/%' and Create_Timestamp = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/West_Data/%') )\nwhere SOURCE_FILE like '/West_Data/%' and  TIMESTAMP = (select MAX(Create_Timestamp) from MERGED_DATA WHERE SOURCE_FILE like '/West_Data/%')"
											}
										]
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": [],
				"lastPublishTime": "2022-06-12T12:20:18Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/WestSource')]",
				"[concat(variables('factoryId'), '/dataflows/WestDataMigrate')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/CentralSource')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Excel",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "Central_Data",
						"container": "tes-rawdata"
					},
					"sheetIndex": 0,
					"firstRowAsHeader": true
				},
				"schema": [
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/CompaniesExcel')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Excel",
				"typeProperties": {
					"sheetName": "companies",
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "group_reference_data.xlsx",
						"container": "tesmetadata"
					},
					"firstRowAsHeader": true
				},
				"schema": [
					{
						"name": "company_id",
						"type": "String"
					},
					{
						"name": "company",
						"type": "String"
					},
					{
						"name": "contact",
						"type": "String"
					},
					{
						"name": "region",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/CompaniesSQL')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "Company_ID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "Company",
						"type": "nvarchar"
					},
					{
						"name": "Contact",
						"type": "nvarchar"
					},
					{
						"name": "Region",
						"type": "nvarchar"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "Companies"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DatavalidationSegment')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Excel",
				"typeProperties": {
					"sheetName": "Segment",
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Data Validation.xlsx",
						"container": "tesmetadata"
					},
					"firstRowAsHeader": true
				},
				"schema": [
					{
						"name": "Segment Allowed",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DatavalidationShipMode')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Excel",
				"typeProperties": {
					"sheetName": "Ship Mode",
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Data Validation.xlsx",
						"container": "tesmetadata"
					},
					"firstRowAsHeader": true
				},
				"schema": [
					{
						"name": "Ship Mode Allowed",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DelimitedText1')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "CSV_files",
						"container": "tes-rawdata"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "order_number",
						"type": "String"
					},
					{
						"name": "ord_date",
						"type": "String"
					},
					{
						"name": "ship_date",
						"type": "String"
					},
					{
						"name": "ship_type",
						"type": "String"
					},
					{
						"name": "customer_key",
						"type": "String"
					},
					{
						"name": "customer_section",
						"type": "String"
					},
					{
						"name": "post_code",
						"type": "String"
					},
					{
						"name": "product_id",
						"type": "String"
					},
					{
						"name": "sales",
						"type": "String"
					},
					{
						"name": "#_items",
						"type": "String"
					},
					{
						"name": "reduction",
						"type": "String"
					},
					{
						"name": "total",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DelimitedText2')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "JSON_Format",
						"container": "tes-rawdata"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DestinationDataset_lpx')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureTableStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureTable",
				"schema": [],
				"typeProperties": {
					"tableName": "Table1"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureTableStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DumpNullMetaRows')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "Error_rows",
						"container": "tesmetadata"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DumpRowstobeFixed')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Error_Rows.csv",
						"folderPath": "Rows_to_be_Fixed",
						"container": "tes-rawdata"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"quoteChar": "\""
				},
				"schema": [
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/EastSource')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "East_Data",
						"container": "tes-rawdata"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "order_number",
						"type": "String"
					},
					{
						"name": "ord_date",
						"type": "String"
					},
					{
						"name": "ship_date",
						"type": "String"
					},
					{
						"name": "ship_type",
						"type": "String"
					},
					{
						"name": "customer_key",
						"type": "String"
					},
					{
						"name": "customer_section",
						"type": "String"
					},
					{
						"name": "post_code",
						"type": "String"
					},
					{
						"name": "product_id",
						"type": "String"
					},
					{
						"name": "sales",
						"type": "String"
					},
					{
						"name": "#_items",
						"type": "String"
					},
					{
						"name": "reduction",
						"type": "String"
					},
					{
						"name": "total",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Json2')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "JSON_Format",
						"container": "tes-rawdata"
					}
				},
				"schema": {
					"type": "object",
					"properties": {
						"sample_data_south": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"Order": {
										"type": "string"
									},
									"Date": {
										"type": "string"
									},
									"Date Shipped": {
										"type": "string"
									},
									"Shipping Method": {
										"type": "string"
									},
									"Customer Number": {
										"type": "string"
									},
									"Segment": {
										"type": "string"
									},
									"Postal Code 1": {
										"type": "string"
									},
									"Product ID": {
										"type": "string"
									},
									"Sales": {
										"type": "string"
									},
									"Quantity": {
										"type": "string"
									},
									"Discount": {
										"type": "string"
									},
									"Profit": {
										"type": "string"
									}
								}
							}
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/MetaDataLogs')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "SOURCE_FILE",
						"type": "nvarchar"
					},
					{
						"name": "SOURCE_ROW_COUNT",
						"type": "int",
						"precision": 10
					},
					{
						"name": "ERROR_ROWS",
						"type": "int",
						"precision": 10
					},
					{
						"name": "DUPLICATE_ROW_COUNT",
						"type": "int",
						"precision": 10
					},
					{
						"name": "IGNORE_ROW_COUNT",
						"type": "int",
						"precision": 10
					},
					{
						"name": "FINAL_COUNT",
						"type": "int",
						"precision": 10
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "META_DATA_LOGS"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/PostalCodesExcel')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Excel",
				"typeProperties": {
					"sheetName": "postal_codes",
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "group_reference_data.xlsx",
						"container": "tesmetadata"
					},
					"firstRowAsHeader": true
				},
				"schema": [
					{
						"name": "postal_code",
						"type": "String"
					},
					{
						"name": "state",
						"type": "String"
					},
					{
						"name": "region",
						"type": "String"
					},
					{
						"name": "country",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/PostalCodesSQL')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "Postal_Code",
						"type": "int",
						"precision": 10
					},
					{
						"name": "State",
						"type": "nvarchar"
					},
					{
						"name": "Region",
						"type": "nvarchar"
					},
					{
						"name": "Country_Region",
						"type": "varchar"
					},
					{
						"name": "Country",
						"type": "nvarchar"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "Postal_Code"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/ProductTypesExcel')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Excel",
				"typeProperties": {
					"sheetName": "product_types",
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "group_reference_data.xlsx",
						"container": "tesmetadata"
					},
					"firstRowAsHeader": true
				},
				"schema": [
					{
						"name": "product_type",
						"type": "String"
					},
					{
						"name": "product_category",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/ProductTypesSQL')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "Product_Type",
						"type": "nvarchar"
					},
					{
						"name": "Product_Category",
						"type": "nvarchar"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "Product_Types"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/ProductsExcel')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Excel",
				"typeProperties": {
					"sheetName": "products",
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "group_reference_data.xlsx",
						"container": "tesmetadata"
					},
					"firstRowAsHeader": true
				},
				"schema": [
					{
						"name": "product_id",
						"type": "String"
					},
					{
						"name": "product_name",
						"type": "String"
					},
					{
						"name": "category",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/ProductsSQL')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "Product_ID",
						"type": "nvarchar"
					},
					{
						"name": "Product_Name",
						"type": "nvarchar"
					},
					{
						"name": "Category",
						"type": "nvarchar"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "Products"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/RowstobeFixed')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Excel",
				"typeProperties": {
					"sheetName": "Sheet1",
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Error_Rows.xlsx",
						"folderPath": "Rows_to_be_Fixed",
						"container": "tes-rawdata"
					},
					"firstRowAsHeader": true
				},
				"schema": [
					{
						"name": "Order_ID",
						"type": "String"
					},
					{
						"name": "Order_date",
						"type": "String"
					},
					{
						"name": "Ship_date",
						"type": "String"
					},
					{
						"name": "Ship_Mode",
						"type": "String"
					},
					{
						"name": "Customer_ID",
						"type": "String"
					},
					{
						"name": "Segment",
						"type": "String"
					},
					{
						"name": "Postal_Code",
						"type": "String"
					},
					{
						"name": "Product ID",
						"type": "String"
					},
					{
						"name": "Sales",
						"type": "String"
					},
					{
						"name": "Quantity",
						"type": "String"
					},
					{
						"name": "Discount",
						"type": "String"
					},
					{
						"name": "Profit",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/SalesLogsSQL')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "SOURCE_FILE",
						"type": "nvarchar"
					},
					{
						"name": "TIMESTAMP",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "SOURCE_ROW_COUNT",
						"type": "int",
						"precision": 10
					},
					{
						"name": "ERROR_ROWS",
						"type": "int",
						"precision": 10
					},
					{
						"name": "DUPLICATE_ROW_COUNT",
						"type": "int",
						"precision": 10
					},
					{
						"name": "FINAL_COUNT",
						"type": "int",
						"precision": 10
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "MERGED_DATA_LOGS"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/SalesSQL')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "Order_ID",
						"type": "nvarchar"
					},
					{
						"name": "Order_Date",
						"type": "date"
					},
					{
						"name": "Ship_Date",
						"type": "date"
					},
					{
						"name": "Ship_Mode",
						"type": "nvarchar"
					},
					{
						"name": "Customer_ID",
						"type": "nvarchar"
					},
					{
						"name": "Segment",
						"type": "nvarchar"
					},
					{
						"name": "Postal_Code",
						"type": "int",
						"precision": 10
					},
					{
						"name": "Product_ID",
						"type": "nvarchar"
					},
					{
						"name": "SALES",
						"type": "decimal",
						"precision": 20,
						"scale": 2
					},
					{
						"name": "QUANTITY",
						"type": "int",
						"precision": 10
					},
					{
						"name": "Discount",
						"type": "float",
						"precision": 15
					},
					{
						"name": "Profit",
						"type": "float",
						"precision": 15
					},
					{
						"name": "Create_Timestamp",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "SOURCE_FILE",
						"type": "nvarchar"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "MERGED_DATA"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/SourceDataset_lpx')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Excel",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "Xlsx_Format1",
						"container": "tes-rawdata"
					},
					"sheetIndex": 0,
					"firstRowAsHeader": true
				},
				"schema": [
					{
						"name": "Order ID",
						"type": "String"
					},
					{
						"name": "Order Date",
						"type": "String"
					},
					{
						"name": "Ship Date",
						"type": "String"
					},
					{
						"name": "Ship Mode",
						"type": "String"
					},
					{
						"name": "Customer ID",
						"type": "String"
					},
					{
						"name": "Segment",
						"type": "String"
					},
					{
						"name": "Postal Code",
						"type": "String"
					},
					{
						"name": "Product ID",
						"type": "String"
					},
					{
						"name": "Sales",
						"type": "String"
					},
					{
						"name": "Quantity",
						"type": "String"
					},
					{
						"name": "Discount",
						"type": "String"
					},
					{
						"name": "Profit",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/SouthSource')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "South_Data",
						"container": "tes-rawdata"
					},
					"encodingName": "UTF-8"
				},
				"schema": {
					"type": "object",
					"properties": {
						"sample_data_south": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"Order": {
										"type": "string"
									},
									"Date": {
										"type": "string"
									},
									"Date Shipped": {
										"type": "string"
									},
									"Shipping Method": {
										"type": "string"
									},
									"Customer Number": {
										"type": "string"
									},
									"Segment": {
										"type": "string"
									},
									"Postal Code 1": {
										"type": "string"
									},
									"Product ID": {
										"type": "string"
									},
									"Sales": {
										"type": "string"
									},
									"Quantity": {
										"type": "string"
									},
									"Discount": {
										"type": "string"
									},
									"Profit": {
										"type": "string"
									}
								}
							}
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/WestSource')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureBlobStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Excel",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "West_Data",
						"container": "tes-rawdata"
					},
					"sheetIndex": 0
				},
				"schema": [
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/AzureBlobStorage1')]",
			"type": "Microsoft.DataFactory/factories/linkedServices",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"connectionString": "[parameters('AzureBlobStorage1_connectionString')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/AzureSqlDatabase1')]",
			"type": "Microsoft.DataFactory/factories/linkedServices",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"connectionString": "[parameters('AzureSqlDatabase1_connectionString')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/AzureTableStorage1')]",
			"type": "Microsoft.DataFactory/factories/linkedServices",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"type": "AzureTableStorage",
				"typeProperties": {
					"connectionString": "[parameters('AzureTableStorage1_connectionString')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/CentralDataMigrate')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CentralSource",
								"type": "DatasetReference"
							},
							"name": "ReadSource"
						},
						{
							"dataset": {
								"referenceName": "DatavalidationSegment",
								"type": "DatasetReference"
							},
							"name": "ReadSegmentAllowed"
						},
						{
							"dataset": {
								"referenceName": "DatavalidationShipMode",
								"type": "DatasetReference"
							},
							"name": "ReadShipModeAllowed"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "SalesSQL",
								"type": "DatasetReference"
							},
							"name": "InsertinSQL",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "DumpRowstobeFixed",
								"type": "DatasetReference"
							},
							"name": "InsertinCSV"
						},
						{
							"dataset": {
								"referenceName": "SalesLogsSQL",
								"type": "DatasetReference"
							},
							"name": "AddLogs1"
						}
					],
					"transformations": [
						{
							"name": "RemoveDuplicates"
						},
						{
							"name": "RowswithNulls"
						},
						{
							"name": "AddColumns"
						},
						{
							"name": "SourceRowCount"
						},
						{
							"name": "ErrorRowCount"
						},
						{
							"name": "DuplicateRowCount"
						},
						{
							"name": "RenameColumns"
						},
						{
							"name": "AddDuplicateRows"
						},
						{
							"name": "AddErrorRows"
						},
						{
							"name": "MergeSegment"
						},
						{
							"name": "MergeShipMode"
						},
						{
							"name": "FixNullValues"
						}
					],
					"scriptLines": [
						"source(output(",
						"          {Order ID} as string,",
						"          {Order Date} as string,",
						"          {Ship Date} as string,",
						"          {Ship Mode} as string,",
						"          {Customer ID} as string,",
						"          Segment as string,",
						"          {Postal Code} as string,",
						"          {Product ID} as string,",
						"          Sales as string,",
						"          Quantity as string,",
						"          Discount as string,",
						"          Profit as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false,",
						"     rowUrlColumn: 'Source_File',",
						"     wildcardPaths:['Central_Data/*.xlsx'],",
						"     mode: 'read') ~> ReadSource",
						"source(output(",
						"          {Segment Allowed} as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadSegmentAllowed",
						"source(output(",
						"          {Ship Mode Allowed} as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadShipModeAllowed",
						"RowswithNulls@Retain aggregate(groupBy({Order ID},",
						"          {Ship Mode Allowed},",
						"          {Customer ID},",
						"          {Segment Allowed},",
						"          {Product ID},",
						"          Source_File,",
						"          TimeStamp,",
						"          {Order Date Converted},",
						"          {Ship Date Converted},",
						"          {Postal Code Converted},",
						"          {Sales Converted},",
						"          {Quantity Converted},",
						"          {Discount Converted},",
						"          {Profit Converted}),",
						"     Dummy = sum(1)) ~> RemoveDuplicates",
						"AddColumns split(!isNull({Order ID}) && !isNull({Order Date Converted}) && !isNull({Ship Date Converted}) && !isNull({Ship Mode Allowed}) && !isNull({Customer ID}) && !isNull({Segment Allowed}) && !isNull({Postal Code Converted}) && !isNull({Product ID}) && !isNull({Sales Converted}) && !isNull({Quantity Converted}) && !isNull({Discount Converted}) && !isNull({Profit Converted}),",
						"     disjoint: false) ~> RowswithNulls@(Retain, Ignore)",
						"MergeShipMode derive(TimeStamp = currentUTC(),",
						"          {Order Date Converted} = toDate({Order Date},'yyyy-MM-dd'),",
						"          {Ship Date Converted} = toDate({Ship Date},'yyyy-MM-dd'),",
						"          {Postal Code Converted} = toInteger({Postal Code}),",
						"          {Sales Converted} = toDouble(Sales),",
						"          {Quantity Converted} = toInteger(Quantity),",
						"          {Discount Converted} = round(toFloat(Discount),2),",
						"          {Profit Converted} = round(toFloat(Profit),2)) ~> AddColumns",
						"AddColumns aggregate(groupBy(Source_File,",
						"          TimeStamp),",
						"     RowCount = sum(1)) ~> SourceRowCount",
						"RowswithNulls@Ignore aggregate(groupBy(Source_File,",
						"          TimeStamp),",
						"     ErrorRowCount = sum(1)) ~> ErrorRowCount",
						"RemoveDuplicates aggregate(groupBy(Source_File,",
						"          TimeStamp),",
						"     DuplicateRowCount = sum(iif(Dummy != 1, Dummy - 1, toLong(0)))) ~> DuplicateRowCount",
						"ReadSource select(mapColumn(",
						"          {Order ID},",
						"          {Order Date},",
						"          {Ship Date},",
						"          {Ship Mode},",
						"          {Customer ID},",
						"          Segment,",
						"          {Postal Code},",
						"          {Product ID},",
						"          Sales,",
						"          Quantity,",
						"          Discount,",
						"          Profit,",
						"          Source_File",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RenameColumns",
						"SourceRowCount, DuplicateRowCount join(SourceRowCount@Source_File == DuplicateRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> AddDuplicateRows",
						"AddDuplicateRows, ErrorRowCount join(SourceRowCount@Source_File == ErrorRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> AddErrorRows",
						"RenameColumns, ReadSegmentAllowed join(fuzzyCompare(Segment, {Segment Allowed}, 85.00),",
						"     joinType:'left',",
						"     matchType:'fuzzy',",
						"     ignoreSpaces: true,",
						"     broadcast: 'off')~> MergeSegment",
						"MergeSegment, ReadShipModeAllowed join(fuzzyCompare({Ship Mode}, {Ship Mode Allowed}, 85.00),",
						"     joinType:'left',",
						"     matchType:'fuzzy',",
						"     ignoreSpaces: true,",
						"     broadcast: 'off')~> MergeShipMode",
						"AddErrorRows derive(DuplicateRowCount = iif(isNull(DuplicateRowCount),0,toInteger(DuplicateRowCount)),",
						"          ErrorRowCount = iif(isNull(ErrorRowCount),0,toInteger(ErrorRowCount))) ~> FixNullValues",
						"RemoveDuplicates sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Order_ID as string,",
						"          Order_Date as date,",
						"          Ship_Date as date,",
						"          Ship_Mode as string,",
						"          Customer_ID as string,",
						"          Segment as string,",
						"          Postal_Code as integer,",
						"          Product_ID as string,",
						"          SALES as decimal(20,2),",
						"          QUANTITY as integer,",
						"          Discount as double,",
						"          Profit as double,",
						"          Create_Timestamp as timestamp,",
						"          SOURCE_FILE as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'allErrors',",
						"     outputRejectedData: true,",
						"     rejectedData_container: 'tes-rawdata',",
						"     rejectedData_folderPath: 'Rows_to_be_Fixed',",
						"     transactionCommit: 'single',",
						"     reportSuccessOnError: false,",
						"     mapColumn(",
						"          Order_ID = {Order ID},",
						"          Order_Date = {Order Date Converted},",
						"          Ship_Date = {Ship Date Converted},",
						"          Ship_Mode = {Ship Mode Allowed},",
						"          Customer_ID = {Customer ID},",
						"          Segment = {Segment Allowed},",
						"          Postal_Code = {Postal Code Converted},",
						"          Product_ID = {Product ID},",
						"          SALES = {Sales Converted},",
						"          QUANTITY = {Quantity Converted},",
						"          Discount = {Discount Converted},",
						"          Profit = {Profit Converted},",
						"          Create_Timestamp = TimeStamp,",
						"          SOURCE_FILE = Source_File",
						"     )) ~> InsertinSQL",
						"RowswithNulls@Ignore sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Column_1 as string,",
						"          Column_2 as string,",
						"          Column_3 as string,",
						"          Column_4 as string,",
						"          Column_5 as string,",
						"          Column_6 as string,",
						"          Column_7 as string,",
						"          Column_8 as string,",
						"          Column_9 as string,",
						"          Column_10 as string,",
						"          Column_11 as string,",
						"          Column_12 as string",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> InsertinCSV",
						"FixNullValues sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          SOURCE_FILE as string,",
						"          TIMESTAMP as timestamp,",
						"          SOURCE_ROW_COUNT as integer,",
						"          ERROR_ROWS as integer,",
						"          DUPLICATE_ROW_COUNT as integer,",
						"          FINAL_COUNT as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          SOURCE_FILE = SourceRowCount@Source_File,",
						"          TIMESTAMP = SourceRowCount@TimeStamp,",
						"          SOURCE_ROW_COUNT = RowCount,",
						"          DUPLICATE_ROW_COUNT = DuplicateRowCount,",
						"          ERROR_ROWS = ErrorRowCount",
						"     )) ~> AddLogs1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/CentralSource')]",
				"[concat(variables('factoryId'), '/datasets/DatavalidationSegment')]",
				"[concat(variables('factoryId'), '/datasets/DatavalidationShipMode')]",
				"[concat(variables('factoryId'), '/datasets/SalesSQL')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]",
				"[concat(variables('factoryId'), '/datasets/DumpRowstobeFixed')]",
				"[concat(variables('factoryId'), '/datasets/SalesLogsSQL')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/CompaniesMetadata')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CompaniesExcel",
								"type": "DatasetReference"
							},
							"name": "ReadSource"
						},
						{
							"dataset": {
								"referenceName": "CompaniesSQL",
								"type": "DatasetReference"
							},
							"name": "ReadSQL"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "CompaniesSQL",
								"type": "DatasetReference"
							},
							"name": "InsertinSQL",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "DumpNullMetaRows",
								"type": "DatasetReference"
							},
							"name": "RecordNullRows"
						},
						{
							"dataset": {
								"referenceName": "MetaDataLogs",
								"type": "DatasetReference"
							},
							"name": "AddLogs"
						}
					],
					"transformations": [
						{
							"name": "CheckforDuplicates"
						},
						{
							"name": "CheckUpdate"
						},
						{
							"name": "MarkUpdates"
						},
						{
							"name": "TransformType"
						},
						{
							"name": "FilterExistingRows"
						},
						{
							"name": "SourceRowCount"
						},
						{
							"name": "DuplicateRowCount"
						},
						{
							"name": "ErrorRowCount"
						},
						{
							"name": "IgnoreRowCount"
						},
						{
							"name": "MergeDuplicateRows"
						},
						{
							"name": "MergeErrorRows"
						},
						{
							"name": "MergeIgnoreRows"
						},
						{
							"name": "FixNulls"
						},
						{
							"name": "AddSourceFile"
						}
					],
					"scriptLines": [
						"source(output(",
						"          company_id as string,",
						"          company as string,",
						"          contact as string,",
						"          region as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadSource",
						"source(output(",
						"          Company_ID as integer,",
						"          Company as string,",
						"          Contact as string,",
						"          Region as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> ReadSQL",
						"AddSourceFile aggregate(groupBy(company_id,",
						"          company,",
						"          contact,",
						"          region,",
						"          Source_File),",
						"     Dummy = sum(1)) ~> CheckforDuplicates",
						"TransformType, ReadSQL join(TransformType@company_id == ReadSQL@Company_ID,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> CheckUpdate",
						"FilterExistingRows@Retain alterRow(updateIf(FilterExistingRows@Retain@company!=FilterExistingRows@Retain@Company||FilterExistingRows@Retain@contact!=FilterExistingRows@Retain@Contact||FilterExistingRows@Retain@region!=FilterExistingRows@Retain@Region)) ~> MarkUpdates",
						"CheckforDuplicates derive(company_id = toInteger(company_id)) ~> TransformType",
						"CheckUpdate split((isNull(ReadSQL@Company_ID) || (CheckforDuplicates@company != ReadSQL@Company || CheckforDuplicates@contact != ReadSQL@Contact || CheckforDuplicates@region != ReadSQL@Region)) \r",
						"&& (!isNull(TransformType@company_id) && !isNull(CheckforDuplicates@company) && !isNull(CheckforDuplicates@contact) && !isNull(CheckforDuplicates@region)),",
						"     isNull(ReadSQL@Company_ID) && (isNull(CheckforDuplicates@company) || isNull(CheckforDuplicates@contact) || isNull(CheckforDuplicates@region)),",
						"     disjoint: false) ~> FilterExistingRows@(Retain, FilterNullRows, Ignore)",
						"AddSourceFile aggregate(groupBy(Source_File),",
						"     SRowCount = sum(1)) ~> SourceRowCount",
						"CheckforDuplicates aggregate(groupBy(Source_File),",
						"     DuplicateRowCount = sum(iif(Dummy != 1, Dummy - 1, toLong(0)))) ~> DuplicateRowCount",
						"FilterExistingRows@FilterNullRows aggregate(groupBy(Source_File),",
						"     ERowcount = sum(1)) ~> ErrorRowCount",
						"FilterExistingRows@Ignore aggregate(groupBy(Source_File),",
						"     IRowCount = sum(1)) ~> IgnoreRowCount",
						"SourceRowCount, DuplicateRowCount join(SourceRowCount@Source_File == DuplicateRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeDuplicateRows",
						"MergeDuplicateRows, ErrorRowCount join(SourceRowCount@Source_File == ErrorRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeErrorRows",
						"MergeErrorRows, IgnoreRowCount join(SourceRowCount@Source_File == IgnoreRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeIgnoreRows",
						"MergeIgnoreRows derive(DuplicateRowCount = iif(isNull(DuplicateRowCount),0,toInteger(DuplicateRowCount)),",
						"          ERowcount = iif(isNull(ERowcount),0,toInteger(ERowcount)),",
						"          IRowCount = iif(isNull(IRowCount),0,toInteger(IRowCount))) ~> FixNulls",
						"ReadSource derive(Source_File = 'Company') ~> AddSourceFile",
						"MarkUpdates sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Company_ID as integer,",
						"          Company as string,",
						"          Contact as string,",
						"          Region as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['Company_ID'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'allErrors',",
						"     outputRejectedData: true,",
						"     rejectedData_container: 'tesmetadata',",
						"     transactionCommit: 'single',",
						"     reportSuccessOnError: false,",
						"     mapColumn(",
						"          Company_ID = FilterExistingRows@Retain@company_id,",
						"          Company = FilterExistingRows@Retain@company,",
						"          Contact = FilterExistingRows@Retain@contact,",
						"          Region = FilterExistingRows@Retain@region",
						"     )) ~> InsertinSQL",
						"FilterExistingRows@FilterNullRows sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RecordNullRows",
						"FixNulls sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          SOURCE_FILE as string,",
						"          SOURCE_ROW_COUNT as integer,",
						"          ERROR_ROWS as integer,",
						"          DUPLICATE_ROW_COUNT as integer,",
						"          IGNORE_ROW_COUNT as integer,",
						"          FINAL_COUNT as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          SOURCE_FILE = SourceRowCount@Source_File,",
						"          SOURCE_ROW_COUNT = SRowCount,",
						"          ERROR_ROWS = ERowcount,",
						"          DUPLICATE_ROW_COUNT = DuplicateRowCount,",
						"          IGNORE_ROW_COUNT = IRowCount",
						"     )) ~> AddLogs"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/CompaniesExcel')]",
				"[concat(variables('factoryId'), '/datasets/CompaniesSQL')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]",
				"[concat(variables('factoryId'), '/datasets/DumpNullMetaRows')]",
				"[concat(variables('factoryId'), '/datasets/MetaDataLogs')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/EastDataMigrate')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EastSource",
								"type": "DatasetReference"
							},
							"name": "ReadSource"
						},
						{
							"dataset": {
								"referenceName": "DatavalidationSegment",
								"type": "DatasetReference"
							},
							"name": "ReadSegmentAllowed"
						},
						{
							"dataset": {
								"referenceName": "DatavalidationShipMode",
								"type": "DatasetReference"
							},
							"name": "ReadShipModeAllowed"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "SalesSQL",
								"type": "DatasetReference"
							},
							"name": "InsertinSQL",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "DumpRowstobeFixed",
								"type": "DatasetReference"
							},
							"name": "InsertinCSV"
						},
						{
							"dataset": {
								"referenceName": "SalesLogsSQL",
								"type": "DatasetReference"
							},
							"name": "AddLogs"
						}
					],
					"transformations": [
						{
							"name": "RemoveDuplicates"
						},
						{
							"name": "RowswithNulls"
						},
						{
							"name": "AddColumns"
						},
						{
							"name": "SourceRowCount"
						},
						{
							"name": "ErrorRowCount"
						},
						{
							"name": "DuplicateRowCount"
						},
						{
							"name": "RenameColumns"
						},
						{
							"name": "AddDuplicateRows"
						},
						{
							"name": "AddErrorRoes"
						},
						{
							"name": "MergeSegment"
						},
						{
							"name": "MergeShipMode"
						},
						{
							"name": "FixNullValues"
						}
					],
					"scriptLines": [
						"source(output(",
						"          order_number as string,",
						"          ord_date as string,",
						"          ship_date as string,",
						"          ship_type as string,",
						"          customer_key as string,",
						"          customer_section as string,",
						"          post_code as string,",
						"          product_id as string,",
						"          sales as string,",
						"          {#_items} as string,",
						"          reduction as string,",
						"          total as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false,",
						"     rowUrlColumn: 'Source_File',",
						"     wildcardPaths:['East_Data/*.csv'],",
						"     mode: 'read') ~> ReadSource",
						"source(output(",
						"          {Segment Allowed} as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadSegmentAllowed",
						"source(output(",
						"          {Ship Mode Allowed} as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadShipModeAllowed",
						"RowswithNulls@Retain aggregate(groupBy({Order ID},",
						"          {Ship Mode Allowed},",
						"          {Customer ID},",
						"          {Segment Allowed},",
						"          {Product ID},",
						"          Source_File,",
						"          TimeStamp,",
						"          {Order Date Converted},",
						"          {Ship Date Converted},",
						"          {Postal Code Converted},",
						"          {Sales Converted},",
						"          {Quantity Converted},",
						"          {Discount Converted},",
						"          {Profit Converted}),",
						"     Dummy = sum(1)) ~> RemoveDuplicates",
						"AddColumns split(!isNull({Order ID}) && !isNull({Order Date Converted}) && !isNull({Ship Date Converted}) && !isNull({Ship Mode Allowed}) && !isNull({Customer ID}) && !isNull({Segment Allowed}) && !isNull({Postal Code Converted}) && !isNull({Postal Code}) && !isNull({Sales Converted}) && !isNull({Quantity Converted}) && !isNull({Discount Converted}) && !isNull({Profit Converted}),",
						"     disjoint: false) ~> RowswithNulls@(Retain, Ignore)",
						"MergeShipMode derive(TimeStamp = currentUTC(),",
						"          {Order Date Converted} = toDate(replace({Order Date},'31/11','30/11'),'dd/MM/yyyy'),",
						"          {Ship Date Converted} = toDate(iif(length({Ship Date}) == 9, replace({Ship Date},'202','/202'), replace({Ship Date},'31/06','30/06')),'dd/MM/yyyy'),",
						"          {Postal Code Converted} = toInteger({Postal Code}),",
						"          {Sales Converted} = toDouble(regexReplace(Sales,'[^.0-9]','')),",
						"          {Quantity Converted} = toInteger(regexReplace(Quantity,'[^.0-9]','')),",
						"          {Discount Converted} = round(toFloat(Discount),2),",
						"          {Profit Converted} = round(toFloat(Profit),2),",
						"          {Product ID} = replace({Product ID}, '*', '')) ~> AddColumns",
						"AddColumns aggregate(groupBy(Source_File,",
						"          TimeStamp),",
						"     RowCount = sum(1)) ~> SourceRowCount",
						"RowswithNulls@Ignore aggregate(groupBy(Source_File,",
						"          TimeStamp),",
						"     ErrorRowCount = sum(1)) ~> ErrorRowCount",
						"RemoveDuplicates aggregate(groupBy(Source_File,",
						"          TimeStamp),",
						"     DuplicateRowCount = sum(iif(Dummy != 1, Dummy - 1, toLong(0)))) ~> DuplicateRowCount",
						"ReadSource select(mapColumn(",
						"          {Order ID} = order_number,",
						"          {Order Date} = ord_date,",
						"          {Ship Date} = ship_date,",
						"          {Ship Mode} = ship_type,",
						"          {Customer ID} = customer_key,",
						"          Segment = customer_section,",
						"          {Postal Code} = post_code,",
						"          {Product ID} = product_id,",
						"          Sales = sales,",
						"          Quantity = {#_items},",
						"          Discount = reduction,",
						"          Profit = total,",
						"          Source_File",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RenameColumns",
						"SourceRowCount, DuplicateRowCount join(SourceRowCount@Source_File == DuplicateRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> AddDuplicateRows",
						"AddDuplicateRows, ErrorRowCount join(SourceRowCount@Source_File == ErrorRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> AddErrorRoes",
						"RenameColumns, ReadSegmentAllowed join(fuzzyCompare(Segment, {Segment Allowed}, 85.00),",
						"     joinType:'left',",
						"     matchType:'fuzzy',",
						"     ignoreSpaces: true,",
						"     broadcast: 'off')~> MergeSegment",
						"MergeSegment, ReadShipModeAllowed join(fuzzyCompare({Ship Mode}, {Ship Mode Allowed}, 85.00),",
						"     joinType:'left',",
						"     matchType:'fuzzy',",
						"     ignoreSpaces: true,",
						"     broadcast: 'off')~> MergeShipMode",
						"AddErrorRoes derive(DuplicateRowCount = iif(isNull(DuplicateRowCount),0,toInteger(DuplicateRowCount)),",
						"          ErrorRowCount = iif(isNull(ErrorRowCount),0,toInteger(ErrorRowCount))) ~> FixNullValues",
						"RemoveDuplicates sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Order_ID as string,",
						"          Order_Date as date,",
						"          Ship_Date as date,",
						"          Ship_Mode as string,",
						"          Customer_ID as string,",
						"          Segment as string,",
						"          Postal_Code as integer,",
						"          Product_ID as string,",
						"          SALES as decimal(20,2),",
						"          QUANTITY as integer,",
						"          Discount as double,",
						"          Profit as double,",
						"          Create_Timestamp as timestamp,",
						"          SOURCE_FILE as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'allErrors',",
						"     outputRejectedData: true,",
						"     rejectedData_container: 'tes-rawdata',",
						"     rejectedData_folderPath: 'Rows_to_be_Fixed',",
						"     transactionCommit: 'single',",
						"     reportSuccessOnError: true,",
						"     mapColumn(",
						"          Order_ID = {Order ID},",
						"          Order_Date = {Order Date Converted},",
						"          Ship_Date = {Ship Date Converted},",
						"          Ship_Mode = {Ship Mode Allowed},",
						"          Customer_ID = {Customer ID},",
						"          Segment = {Segment Allowed},",
						"          Postal_Code = {Postal Code Converted},",
						"          Product_ID = {Product ID},",
						"          SALES = {Sales Converted},",
						"          QUANTITY = {Quantity Converted},",
						"          Discount = {Discount Converted},",
						"          Profit = {Profit Converted},",
						"          Create_Timestamp = TimeStamp,",
						"          SOURCE_FILE = Source_File",
						"     )) ~> InsertinSQL",
						"RowswithNulls@Ignore sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Column_1 as string,",
						"          Column_2 as string,",
						"          Column_3 as string,",
						"          Column_4 as string,",
						"          Column_5 as string,",
						"          Column_6 as string,",
						"          Column_7 as string,",
						"          Column_8 as string,",
						"          Column_9 as string,",
						"          Column_10 as string,",
						"          Column_11 as string,",
						"          Column_12 as string",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> InsertinCSV",
						"FixNullValues sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          SOURCE_FILE as string,",
						"          TIMESTAMP as timestamp,",
						"          SOURCE_ROW_COUNT as integer,",
						"          ERROR_ROWS as integer,",
						"          DUPLICATE_ROW_COUNT as integer,",
						"          FINAL_COUNT as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          SOURCE_FILE = SourceRowCount@Source_File,",
						"          TIMESTAMP = SourceRowCount@TimeStamp,",
						"          SOURCE_ROW_COUNT = RowCount,",
						"          ERROR_ROWS = ErrorRowCount,",
						"          DUPLICATE_ROW_COUNT = DuplicateRowCount",
						"     )) ~> AddLogs"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/EastSource')]",
				"[concat(variables('factoryId'), '/datasets/DatavalidationSegment')]",
				"[concat(variables('factoryId'), '/datasets/DatavalidationShipMode')]",
				"[concat(variables('factoryId'), '/datasets/SalesSQL')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]",
				"[concat(variables('factoryId'), '/datasets/DumpRowstobeFixed')]",
				"[concat(variables('factoryId'), '/datasets/SalesLogsSQL')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/LoadSouthSourceCount')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "SouthSource",
								"type": "DatasetReference"
							},
							"name": "Json"
						}
					],
					"sinks": [
						{
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "FlattenJson"
						},
						{
							"name": "aggregate1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          sample_data_south as (Order as string, Date as string, {Date Shipped} as string, {Shipping Method} as string, {Customer Number} as string, Segment as string, {Postal Code 1} as string, {Product ID} as string, Sales as string, Quantity as string, Discount as string, Profit as string)[]",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false,",
						"     rowUrlColumn: 'Source File',",
						"     documentForm: 'documentPerLine',",
						"     mode: 'read') ~> Json",
						"Json foldDown(unroll(sample_data_south),",
						"     mapColumn(",
						"          {Customer ID} = sample_data_south.{Customer Number},",
						"          {Order Date} = sample_data_south.Date,",
						"          {Ship Date} = sample_data_south.{Date Shipped},",
						"          Discount = sample_data_south.Discount,",
						"          {Order ID} = sample_data_south.Order,",
						"          {Postal Code} = sample_data_south.{Postal Code 1},",
						"          {Product ID} = sample_data_south.{Product ID},",
						"          Profit = sample_data_south.Profit,",
						"          Quantity = sample_data_south.Quantity,",
						"          Sales = sample_data_south.Sales,",
						"          Segment = sample_data_south.Segment,",
						"          {Ship Mode} = sample_data_south.{Shipping Method},",
						"          {Source File}",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> FlattenJson",
						"FlattenJson aggregate(groupBy({Source File}),",
						"     RowCount = sum(1)) ~> aggregate1",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: true,",
						"     saveOrder: 1) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/SouthSource')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/PostalCodeMetadata_v2')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "PostalCodesExcel",
								"type": "DatasetReference"
							},
							"name": "ReadSource"
						},
						{
							"dataset": {
								"referenceName": "PostalCodesSQL",
								"type": "DatasetReference"
							},
							"name": "ReadSQL"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "PostalCodesSQL",
								"type": "DatasetReference"
							},
							"name": "InsertinSQL",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "DumpNullMetaRows",
								"type": "DatasetReference"
							},
							"name": "RecordNullRows"
						},
						{
							"dataset": {
								"referenceName": "MetaDataLogs",
								"type": "DatasetReference"
							},
							"name": "AddLogs"
						}
					],
					"transformations": [
						{
							"name": "CheckforDuplicates"
						},
						{
							"name": "CheckUpdate"
						},
						{
							"name": "MarkUpdates"
						},
						{
							"name": "TransformType"
						},
						{
							"name": "FilterExistingRows"
						},
						{
							"name": "SourceRowCount"
						},
						{
							"name": "DuplicateRowCount"
						},
						{
							"name": "ErrorRowCount"
						},
						{
							"name": "IgnoreRowCount"
						},
						{
							"name": "MergeDuplicateRows"
						},
						{
							"name": "MergeErrorRows"
						},
						{
							"name": "MergeIgnoreRows"
						},
						{
							"name": "FixNulls"
						},
						{
							"name": "AddSourceFile"
						}
					],
					"scriptLines": [
						"source(output(",
						"          postal_code as string,",
						"          state as string,",
						"          region as string,",
						"          country as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadSource",
						"source(output(",
						"          Postal_Code as integer,",
						"          State as string,",
						"          Region as string,",
						"          Country_Region as string,",
						"          Country as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> ReadSQL",
						"AddSourceFile aggregate(groupBy(postal_code,",
						"          state,",
						"          region,",
						"          country,",
						"          Source_File),",
						"     Dummy = sum(1)) ~> CheckforDuplicates",
						"TransformType, ReadSQL join(TransformType@postal_code == ReadSQL@Postal_Code,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> CheckUpdate",
						"FilterExistingRows@Retain alterRow(updateIf(FilterExistingRows@Retain@state!=FilterExistingRows@Retain@State||FilterExistingRows@Retain@region!=FilterExistingRows@Retain@Region||FilterExistingRows@Retain@country!=FilterExistingRows@Retain@Country||FilterExistingRows@Retain@Country_Region!=FilterExistingRows@Retain@Country_Region)) ~> MarkUpdates",
						"CheckforDuplicates derive(postal_code = toInteger(postal_code),",
						"          Country_Region = case(region == 'East', 'Eastern US', case(region == 'West', 'Western US', case(region == 'Central', 'Central US', case(region == 'South', 'Southern US', ''))))) ~> TransformType",
						"CheckUpdate split((isNull(ReadSQL@Postal_Code) || (CheckforDuplicates@state != ReadSQL@State || CheckforDuplicates@region != ReadSQL@Region || CheckforDuplicates@country != ReadSQL@Country || TransformType@Country_Region != ReadSQL@Country_Region) )\r",
						"&& (!isNull(TransformType@postal_code) && !isNull(CheckforDuplicates@state) && !isNull(CheckforDuplicates@region) && !isNull(CheckforDuplicates@country) && !isNull(TransformType@Country_Region)),",
						"     (isNull(TransformType@postal_code) || isNull(CheckforDuplicates@state) || isNull(CheckforDuplicates@region) || isNull(CheckforDuplicates@country) || isNull(TransformType@Country_Region)),",
						"     disjoint: false) ~> FilterExistingRows@(Retain, FilterNullRows, Ignore)",
						"AddSourceFile aggregate(groupBy(Source_File),",
						"     SRowCount = sum(1)) ~> SourceRowCount",
						"CheckforDuplicates aggregate(groupBy(Source_File),",
						"     DuplicateRowCount = sum(iif(Dummy != 1, Dummy - 1, toLong(0)))) ~> DuplicateRowCount",
						"FilterExistingRows@FilterNullRows aggregate(groupBy(Source_File),",
						"     ERowcount = sum(1)) ~> ErrorRowCount",
						"FilterExistingRows@Ignore aggregate(groupBy(Source_File),",
						"     IRowCount = sum(1)) ~> IgnoreRowCount",
						"SourceRowCount, DuplicateRowCount join(SourceRowCount@Source_File == DuplicateRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeDuplicateRows",
						"MergeDuplicateRows, ErrorRowCount join(SourceRowCount@Source_File == ErrorRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeErrorRows",
						"MergeErrorRows, IgnoreRowCount join(SourceRowCount@Source_File == IgnoreRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeIgnoreRows",
						"MergeIgnoreRows derive(DuplicateRowCount = iif(isNull(DuplicateRowCount),0,toInteger(DuplicateRowCount)),",
						"          ERowcount = iif(isNull(ERowcount),0,toInteger(ERowcount)),",
						"          IRowCount = iif(isNull(IRowCount),0,toInteger(IRowCount))) ~> FixNulls",
						"ReadSource derive(Source_File = 'PostalCode') ~> AddSourceFile",
						"MarkUpdates sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Postal_Code as integer,",
						"          State as string,",
						"          Region as string,",
						"          Country_Region as string,",
						"          Country as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['Postal_Code'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'allErrors',",
						"     outputRejectedData: true,",
						"     rejectedData_container: 'tesmetadata',",
						"     transactionCommit: 'single',",
						"     reportSuccessOnError: false,",
						"     mapColumn(",
						"          Postal_Code = FilterExistingRows@Retain@postal_code,",
						"          State = FilterExistingRows@Retain@state,",
						"          Region = FilterExistingRows@Retain@region,",
						"          Country_Region = FilterExistingRows@Retain@Country_Region,",
						"          Country = FilterExistingRows@Retain@country",
						"     )) ~> InsertinSQL",
						"FilterExistingRows@FilterNullRows sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RecordNullRows",
						"FixNulls sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          SOURCE_FILE as string,",
						"          SOURCE_ROW_COUNT as integer,",
						"          ERROR_ROWS as integer,",
						"          DUPLICATE_ROW_COUNT as integer,",
						"          IGNORE_ROW_COUNT as integer,",
						"          FINAL_COUNT as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          SOURCE_FILE = SourceRowCount@Source_File,",
						"          SOURCE_ROW_COUNT = SRowCount,",
						"          ERROR_ROWS = ERowcount,",
						"          DUPLICATE_ROW_COUNT = DuplicateRowCount,",
						"          IGNORE_ROW_COUNT = IRowCount",
						"     )) ~> AddLogs"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/PostalCodesExcel')]",
				"[concat(variables('factoryId'), '/datasets/PostalCodesSQL')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]",
				"[concat(variables('factoryId'), '/datasets/DumpNullMetaRows')]",
				"[concat(variables('factoryId'), '/datasets/MetaDataLogs')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/PostalCodesMetadata')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "PostalCodesExcel",
								"type": "DatasetReference"
							},
							"name": "ReadSource"
						},
						{
							"dataset": {
								"referenceName": "PostalCodesSQL",
								"type": "DatasetReference"
							},
							"name": "ReadSQL"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "PostalCodesSQL",
								"type": "DatasetReference"
							},
							"name": "InsertinSQL"
						}
					],
					"transformations": [
						{
							"name": "CheckforDuplicates"
						},
						{
							"name": "MergeSources"
						},
						{
							"name": "MarkUpdates"
						},
						{
							"name": "TransformType"
						},
						{
							"name": "FilterExistingRows"
						}
					],
					"scriptLines": [
						"source(output(",
						"          postal_code as string,",
						"          state as string,",
						"          region as string,",
						"          country as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadSource",
						"source(output(",
						"          Postal_Code as integer,",
						"          State as string,",
						"          Region as string,",
						"          Country_Region as string,",
						"          Country as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> ReadSQL",
						"ReadSource aggregate(groupBy(postal_code,",
						"          state,",
						"          region,",
						"          country),",
						"     Dummy = sum(1)) ~> CheckforDuplicates",
						"TransformType, ReadSQL join(TransformType@postal_code == ReadSQL@Postal_Code,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeSources",
						"FilterExistingRows@Retain alterRow(updateIf(FilterExistingRows@Retain@state!=FilterExistingRows@Retain@State||FilterExistingRows@Retain@region!=FilterExistingRows@Retain@Region||FilterExistingRows@Retain@country!=FilterExistingRows@Retain@Country||FilterExistingRows@Retain@Country_Region!=FilterExistingRows@Retain@Country_Region)) ~> MarkUpdates",
						"CheckforDuplicates derive(postal_code = toInteger(postal_code),",
						"          Country_Region = case(region == 'East', 'Eastern US', case(region == 'West', 'Western US', case(region == 'Central', 'Central US', case(region == 'South', 'Southern US', ''))))) ~> TransformType",
						"MergeSources split((TransformType@postal_code != ReadSQL@Postal_Code || CheckforDuplicates@state != ReadSQL@State || CheckforDuplicates@region != ReadSQL@Region || CheckforDuplicates@country != ReadSQL@Country || TransformType@Country_Region != ReadSQL@Country_Region) || (isNull(ReadSQL@Postal_Code) && isNull(ReadSQL@State) && isNull(ReadSQL@Region) && isNull(ReadSQL@Country)),",
						"     disjoint: false) ~> FilterExistingRows@(Retain, Ignore)",
						"MarkUpdates sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Postal_Code as integer,",
						"          State as string,",
						"          Region as string,",
						"          Country_Region as string,",
						"          Country as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['Postal_Code'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Postal_Code = FilterExistingRows@Retain@postal_code,",
						"          State = FilterExistingRows@Retain@state,",
						"          Region = FilterExistingRows@Retain@region,",
						"          Country = FilterExistingRows@Retain@country,",
						"          Country_Region = FilterExistingRows@Retain@Country_Region",
						"     )) ~> InsertinSQL"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/PostalCodesExcel')]",
				"[concat(variables('factoryId'), '/datasets/PostalCodesSQL')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/ProductTypesMetadata')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ProductTypesExcel",
								"type": "DatasetReference"
							},
							"name": "ReadSource"
						},
						{
							"dataset": {
								"referenceName": "ProductTypesSQL",
								"type": "DatasetReference"
							},
							"name": "ReadSQL"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ProductTypesSQL",
								"type": "DatasetReference"
							},
							"name": "InsertinSQL"
						}
					],
					"transformations": [
						{
							"name": "CheckforDuplicates"
						},
						{
							"name": "MergeSources"
						},
						{
							"name": "MarkUpdates"
						},
						{
							"name": "FilterExistingRows"
						}
					],
					"scriptLines": [
						"source(output(",
						"          product_type as string,",
						"          product_category as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadSource",
						"source(output(",
						"          Product_Type as string,",
						"          Product_Category as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> ReadSQL",
						"ReadSource aggregate(groupBy(product_type,",
						"          product_category),",
						"     Dummy = sum(1)) ~> CheckforDuplicates",
						"CheckforDuplicates, ReadSQL join(CheckforDuplicates@product_type == ReadSQL@Product_Type,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeSources",
						"FilterExistingRows@Retain alterRow(updateIf(FilterExistingRows@Retain@product_category!=FilterExistingRows@Retain@Product_Category)) ~> MarkUpdates",
						"MergeSources split((CheckforDuplicates@product_type != ReadSQL@Product_Type || CheckforDuplicates@product_category != ReadSQL@Product_Category) || (isNull(ReadSQL@Product_Type) && isNull(ReadSQL@Product_Category)),",
						"     disjoint: false) ~> FilterExistingRows@(Retain, Ignore)",
						"MarkUpdates sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Product_Type as string,",
						"          Product_Category as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['Product_Type'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Product_Type = FilterExistingRows@Retain@product_type,",
						"          Product_Category = FilterExistingRows@Retain@product_category",
						"     )) ~> InsertinSQL"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ProductTypesExcel')]",
				"[concat(variables('factoryId'), '/datasets/ProductTypesSQL')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/ProductTypesMetadata_v2')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ProductTypesExcel",
								"type": "DatasetReference"
							},
							"name": "ReadSource"
						},
						{
							"dataset": {
								"referenceName": "ProductTypesSQL",
								"type": "DatasetReference"
							},
							"name": "ReadSQL"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ProductTypesSQL",
								"type": "DatasetReference"
							},
							"name": "InsertinSQL",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "DumpNullMetaRows",
								"type": "DatasetReference"
							},
							"name": "RecordNullRows"
						},
						{
							"dataset": {
								"referenceName": "MetaDataLogs",
								"type": "DatasetReference"
							},
							"name": "AddLogs"
						}
					],
					"transformations": [
						{
							"name": "CheckforDuplicates"
						},
						{
							"name": "CheckUpdate"
						},
						{
							"name": "MarkUpdates"
						},
						{
							"name": "FilterExistingRows"
						},
						{
							"name": "SourceRowCount"
						},
						{
							"name": "DuplicateRowCount"
						},
						{
							"name": "ErrorRowCount"
						},
						{
							"name": "IgnoreRowCount"
						},
						{
							"name": "MergeDuplicateRows"
						},
						{
							"name": "MergeErrorRows"
						},
						{
							"name": "MergeIgnoreRows"
						},
						{
							"name": "FixNulls"
						},
						{
							"name": "AddSourceFile"
						}
					],
					"scriptLines": [
						"source(output(",
						"          product_type as string,",
						"          product_category as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadSource",
						"source(output(",
						"          Product_Type as string,",
						"          Product_Category as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> ReadSQL",
						"AddSourceFile aggregate(groupBy(product_type,",
						"          product_category,",
						"          Source_File),",
						"     Dummy = sum(1)) ~> CheckforDuplicates",
						"CheckforDuplicates, ReadSQL join(CheckforDuplicates@product_type == ReadSQL@Product_Type,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> CheckUpdate",
						"FilterExistingRows@Retain alterRow(updateIf(FilterExistingRows@Retain@product_category!=FilterExistingRows@Retain@Product_Category)) ~> MarkUpdates",
						"CheckUpdate split((isNull(ReadSQL@Product_Type) || CheckforDuplicates@product_category != CheckforDuplicates@product_category ) \r",
						"&& (!isNull(CheckforDuplicates@product_type) && !isNull(CheckforDuplicates@product_category)),",
						"     (isNull(CheckforDuplicates@product_type) || isNull(CheckforDuplicates@product_category) ),",
						"     disjoint: false) ~> FilterExistingRows@(Retain, FilterNullRows, Ignore)",
						"AddSourceFile aggregate(groupBy(Source_File),",
						"     SRowCount = sum(1)) ~> SourceRowCount",
						"CheckforDuplicates aggregate(groupBy(Source_File),",
						"     DuplicateRowCount = sum(iif(Dummy != 1, Dummy - 1, toLong(0)))) ~> DuplicateRowCount",
						"FilterExistingRows@FilterNullRows aggregate(groupBy(Source_File),",
						"     ERowcount = sum(1)) ~> ErrorRowCount",
						"FilterExistingRows@Ignore aggregate(groupBy(Source_File),",
						"     IRowCount = sum(1)) ~> IgnoreRowCount",
						"SourceRowCount, DuplicateRowCount join(SourceRowCount@Source_File == DuplicateRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeDuplicateRows",
						"MergeDuplicateRows, ErrorRowCount join(SourceRowCount@Source_File == ErrorRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeErrorRows",
						"MergeErrorRows, IgnoreRowCount join(SourceRowCount@Source_File == IgnoreRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeIgnoreRows",
						"MergeIgnoreRows derive(DuplicateRowCount = iif(isNull(DuplicateRowCount),0,toInteger(DuplicateRowCount)),",
						"          ERowcount = iif(isNull(ERowcount),0,toInteger(ERowcount)),",
						"          IRowCount = iif(isNull(IRowCount),0,toInteger(IRowCount))) ~> FixNulls",
						"ReadSource derive(Source_File = 'ProductTypes') ~> AddSourceFile",
						"MarkUpdates sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Product_Type as string,",
						"          Product_Category as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['Product_Type'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'allErrors',",
						"     outputRejectedData: true,",
						"     rejectedData_container: 'tesmetadata',",
						"     transactionCommit: 'single',",
						"     reportSuccessOnError: false,",
						"     mapColumn(",
						"          Product_Type = FilterExistingRows@Retain@product_type,",
						"          Product_Category = FilterExistingRows@Retain@product_category",
						"     )) ~> InsertinSQL",
						"FilterExistingRows@FilterNullRows sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RecordNullRows",
						"FixNulls sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          SOURCE_FILE as string,",
						"          SOURCE_ROW_COUNT as integer,",
						"          ERROR_ROWS as integer,",
						"          DUPLICATE_ROW_COUNT as integer,",
						"          IGNORE_ROW_COUNT as integer,",
						"          FINAL_COUNT as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          SOURCE_FILE = SourceRowCount@Source_File,",
						"          SOURCE_ROW_COUNT = SRowCount,",
						"          ERROR_ROWS = ERowcount,",
						"          DUPLICATE_ROW_COUNT = DuplicateRowCount,",
						"          IGNORE_ROW_COUNT = IRowCount",
						"     )) ~> AddLogs"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ProductTypesExcel')]",
				"[concat(variables('factoryId'), '/datasets/ProductTypesSQL')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]",
				"[concat(variables('factoryId'), '/datasets/DumpNullMetaRows')]",
				"[concat(variables('factoryId'), '/datasets/MetaDataLogs')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/ProductsMetadata')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ProductsExcel",
								"type": "DatasetReference"
							},
							"name": "ReadSource"
						},
						{
							"dataset": {
								"referenceName": "ProductsSQL",
								"type": "DatasetReference"
							},
							"name": "ReadSQL"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ProductsSQL",
								"type": "DatasetReference"
							},
							"name": "InsertinSQL"
						}
					],
					"transformations": [
						{
							"name": "CheckforDuplicates"
						},
						{
							"name": "MergeSources"
						},
						{
							"name": "MarkUpdates"
						},
						{
							"name": "FilterExistingRows"
						}
					],
					"scriptLines": [
						"source(output(",
						"          product_id as string,",
						"          product_name as string,",
						"          category as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadSource",
						"source(output(",
						"          Product_ID as string,",
						"          Product_Name as string,",
						"          Category as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> ReadSQL",
						"ReadSource aggregate(groupBy(product_id,",
						"          product_name,",
						"          category),",
						"     Dummy = sum(1)) ~> CheckforDuplicates",
						"CheckforDuplicates, ReadSQL join(CheckforDuplicates@product_id == ReadSQL@Product_ID,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeSources",
						"FilterExistingRows@Retain alterRow(updateIf(FilterExistingRows@Retain@product_name!=FilterExistingRows@Retain@Product_Name||FilterExistingRows@Retain@category!=FilterExistingRows@Retain@Category)) ~> MarkUpdates",
						"MergeSources split((CheckforDuplicates@product_id != ReadSQL@Product_ID || CheckforDuplicates@product_name != ReadSQL@Product_Name || CheckforDuplicates@category != ReadSQL@Category) || (isNull(ReadSQL@Product_ID) && isNull(ReadSQL@Product_Name) && isNull(ReadSQL@Category)),",
						"     disjoint: false) ~> FilterExistingRows@(Retain, Ignore)",
						"MarkUpdates sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Product_ID as string,",
						"          Product_Name as string,",
						"          Category as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['Product_ID'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Product_ID = FilterExistingRows@Retain@product_id,",
						"          Product_Name = FilterExistingRows@Retain@product_name,",
						"          Category = FilterExistingRows@Retain@category",
						"     )) ~> InsertinSQL"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ProductsExcel')]",
				"[concat(variables('factoryId'), '/datasets/ProductsSQL')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/ProductsMetadata_v2')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ProductsExcel",
								"type": "DatasetReference"
							},
							"name": "ReadSource"
						},
						{
							"dataset": {
								"referenceName": "ProductsSQL",
								"type": "DatasetReference"
							},
							"name": "ReadSQL"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ProductsSQL",
								"type": "DatasetReference"
							},
							"name": "InsertinSQL",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "DumpNullMetaRows",
								"type": "DatasetReference"
							},
							"name": "RecordNullRows"
						},
						{
							"dataset": {
								"referenceName": "MetaDataLogs",
								"type": "DatasetReference"
							},
							"name": "AddLogs"
						}
					],
					"transformations": [
						{
							"name": "CheckforDuplicates"
						},
						{
							"name": "CheckUpdate"
						},
						{
							"name": "MarkUpdates"
						},
						{
							"name": "FilterExistingRows"
						},
						{
							"name": "SourceRowCount"
						},
						{
							"name": "DuplicateRowCount"
						},
						{
							"name": "ErrorRowCount"
						},
						{
							"name": "IgnoreRowCount"
						},
						{
							"name": "MergeDuplicateRows"
						},
						{
							"name": "MergeErrorRows"
						},
						{
							"name": "MergeIgnoreRows"
						},
						{
							"name": "FixNulls"
						},
						{
							"name": "AddSourceFile"
						}
					],
					"scriptLines": [
						"source(output(",
						"          product_id as string,",
						"          product_name as string,",
						"          category as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadSource",
						"source(output(",
						"          Product_ID as string,",
						"          Product_Name as string,",
						"          Category as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> ReadSQL",
						"AddSourceFile aggregate(groupBy(product_id,",
						"          product_name,",
						"          category,",
						"          Source_File),",
						"     Dummy = sum(1)) ~> CheckforDuplicates",
						"CheckforDuplicates, ReadSQL join(CheckforDuplicates@product_id == ReadSQL@Product_ID,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> CheckUpdate",
						"FilterExistingRows@Retain alterRow(updateIf(FilterExistingRows@Retain@category!=FilterExistingRows@Retain@Category||FilterExistingRows@Retain@product_name!=FilterExistingRows@Retain@Product_Name)) ~> MarkUpdates",
						"CheckUpdate split((isNull(ReadSQL@Product_ID) || (CheckforDuplicates@product_name != CheckforDuplicates@product_name || CheckforDuplicates@category != ReadSQL@Category)) \r",
						"&& (!isNull(CheckforDuplicates@product_id) && !isNull(CheckforDuplicates@product_name) && !isNull(CheckforDuplicates@category)),",
						"     (isNull(CheckforDuplicates@product_id) || isNull(CheckforDuplicates@product_name) || isNull(CheckforDuplicates@category)),",
						"     disjoint: false) ~> FilterExistingRows@(Retain, FilterNullRows, Ignore)",
						"AddSourceFile aggregate(groupBy(Source_File),",
						"     SRowCount = sum(1)) ~> SourceRowCount",
						"CheckforDuplicates aggregate(groupBy(Source_File),",
						"     DuplicateRowCount = sum(iif(Dummy != 1, Dummy - 1, toLong(0)))) ~> DuplicateRowCount",
						"FilterExistingRows@FilterNullRows aggregate(groupBy(Source_File),",
						"     ERowcount = sum(1)) ~> ErrorRowCount",
						"FilterExistingRows@Ignore aggregate(groupBy(Source_File),",
						"     IRowCount = sum(1)) ~> IgnoreRowCount",
						"SourceRowCount, DuplicateRowCount join(SourceRowCount@Source_File == DuplicateRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeDuplicateRows",
						"MergeDuplicateRows, ErrorRowCount join(SourceRowCount@Source_File == ErrorRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeErrorRows",
						"MergeErrorRows, IgnoreRowCount join(SourceRowCount@Source_File == IgnoreRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> MergeIgnoreRows",
						"MergeIgnoreRows derive(DuplicateRowCount = iif(isNull(DuplicateRowCount),0,toInteger(DuplicateRowCount)),",
						"          ERowcount = iif(isNull(ERowcount),0,toInteger(ERowcount)),",
						"          IRowCount = iif(isNull(IRowCount),0,toInteger(IRowCount))) ~> FixNulls",
						"ReadSource derive(Source_File = 'Products') ~> AddSourceFile",
						"MarkUpdates sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Product_ID as string,",
						"          Product_Name as string,",
						"          Category as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['Product_ID'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'allErrors',",
						"     outputRejectedData: true,",
						"     rejectedData_container: 'tesmetadata',",
						"     transactionCommit: 'single',",
						"     reportSuccessOnError: false,",
						"     mapColumn(",
						"          Product_ID = FilterExistingRows@Retain@product_id,",
						"          Product_Name = FilterExistingRows@Retain@product_name,",
						"          Category = FilterExistingRows@Retain@category",
						"     )) ~> InsertinSQL",
						"FilterExistingRows@FilterNullRows sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RecordNullRows",
						"FixNulls sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          SOURCE_FILE as string,",
						"          SOURCE_ROW_COUNT as integer,",
						"          ERROR_ROWS as integer,",
						"          DUPLICATE_ROW_COUNT as integer,",
						"          IGNORE_ROW_COUNT as integer,",
						"          FINAL_COUNT as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          SOURCE_FILE = SourceRowCount@Source_File,",
						"          SOURCE_ROW_COUNT = SRowCount,",
						"          ERROR_ROWS = ERowcount,",
						"          DUPLICATE_ROW_COUNT = DuplicateRowCount,",
						"          IGNORE_ROW_COUNT = IRowCount",
						"     )) ~> AddLogs"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ProductsExcel')]",
				"[concat(variables('factoryId'), '/datasets/ProductsSQL')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]",
				"[concat(variables('factoryId'), '/datasets/DumpNullMetaRows')]",
				"[concat(variables('factoryId'), '/datasets/MetaDataLogs')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/SouthDataMigrate')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "SouthSource",
								"type": "DatasetReference"
							},
							"name": "ReadSource"
						},
						{
							"dataset": {
								"referenceName": "DatavalidationSegment",
								"type": "DatasetReference"
							},
							"name": "ReadSegmentAllowed"
						},
						{
							"dataset": {
								"referenceName": "DatavalidationShipMode",
								"type": "DatasetReference"
							},
							"name": "ReadShipModeAllowed"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "SalesSQL",
								"type": "DatasetReference"
							},
							"name": "InsertinSQL",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "DumpRowstobeFixed",
								"type": "DatasetReference"
							},
							"name": "InsertinCSV"
						},
						{
							"dataset": {
								"referenceName": "SalesLogsSQL",
								"type": "DatasetReference"
							},
							"name": "AddLogs"
						}
					],
					"transformations": [
						{
							"name": "RemoveDuplicates"
						},
						{
							"name": "RowswithNulls"
						},
						{
							"name": "AddColumns"
						},
						{
							"name": "SourceRowCount"
						},
						{
							"name": "ErrorRowCounts"
						},
						{
							"name": "DuplicateRowCounts"
						},
						{
							"name": "AddDuplicateRows"
						},
						{
							"name": "AddErrorRoes"
						},
						{
							"name": "FlattenandRenameColumns"
						},
						{
							"name": "MergeSegment"
						},
						{
							"name": "MergeShipMode"
						},
						{
							"name": "FixNullValues"
						}
					],
					"scriptLines": [
						"source(output(",
						"          sample_data_south as (Order as string, Date as string, {Date Shipped} as string, {Shipping Method} as string, {Customer Number} as string, Segment as string, {Postal Code 1} as string, {Product ID} as string, Sales as string, Quantity as string, Discount as string, Profit as string)[]",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false,",
						"     rowUrlColumn: 'Source_File',",
						"     documentForm: 'documentPerLine',",
						"     wildcardPaths:['South_Data/*.json'],",
						"     mode: 'read') ~> ReadSource",
						"source(output(",
						"          {Segment Allowed} as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadSegmentAllowed",
						"source(output(",
						"          {Ship Mode Allowed} as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadShipModeAllowed",
						"RowswithNulls@Retain aggregate(groupBy({Order ID},",
						"          {Ship Mode Allowed},",
						"          {Customer ID},",
						"          {Segment Allowed},",
						"          {Product ID},",
						"          Source_File,",
						"          TimeStamp,",
						"          {Order Date Converted},",
						"          {Ship Date Converted},",
						"          {Postal Code Converted},",
						"          {Sales Converted},",
						"          {Quantity Converted},",
						"          {Discount Converted},",
						"          {Profit Converted}),",
						"     Dummy = sum(1)) ~> RemoveDuplicates",
						"AddColumns split(!isNull({Order ID}) && !isNull({Order Date Converted}) && !isNull({Ship Date Converted}) && !isNull({Ship Mode Allowed}) && !isNull({Customer ID}) && !isNull({Segment Allowed}) && !isNull({Postal Code Converted}) && !isNull({Product ID}) && !isNull({Sales Converted}) && !isNull({Quantity Converted}) && !isNull({Discount Converted}) && !isNull({Profit Converted}),",
						"     disjoint: false) ~> RowswithNulls@(Retain, Ignore)",
						"MergeShipMode derive(TimeStamp = currentUTC(),",
						"          {Order Date Converted} = iif(length({Order Date}) ==9,toDate(replace({Order Date}, '202', '/2'),'dd/MM/yy'),toDate({Order Date} ,'MM/dd/yy')),",
						"          {Ship Date Converted} = toDate({Ship Date},'MM/dd/yy'),",
						"          {Postal Code Converted} = toInteger({Postal Code}),",
						"          {Sales Converted} = toDouble(Sales),",
						"          {Quantity Converted} = toInteger(Quantity),",
						"          {Discount Converted} = round(toFloat(Discount),2),",
						"          {Profit Converted} = round(toFloat(regexReplace(Profit,'[^.0-9]','')),2)) ~> AddColumns",
						"AddColumns aggregate(groupBy(Source_File,",
						"          TimeStamp),",
						"     RowCount = sum(1)) ~> SourceRowCount",
						"RowswithNulls@Ignore aggregate(groupBy(Source_File,",
						"          TimeStamp),",
						"     ErrorRowCount = sum(1)) ~> ErrorRowCounts",
						"RemoveDuplicates aggregate(groupBy(Source_File,",
						"          TimeStamp),",
						"     DuplicateRowCount = sum(iif(Dummy != 1, Dummy - 1, toLong(0)))) ~> DuplicateRowCounts",
						"SourceRowCount, DuplicateRowCounts join(SourceRowCount@Source_File == DuplicateRowCounts@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> AddDuplicateRows",
						"AddDuplicateRows, ErrorRowCounts join(SourceRowCount@Source_File == ErrorRowCounts@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> AddErrorRoes",
						"ReadSource foldDown(unroll(sample_data_south),",
						"     mapColumn(",
						"          {Order ID} = sample_data_south.Order,",
						"          {Order Date} = sample_data_south.Date,",
						"          {Ship Date} = sample_data_south.{Date Shipped},",
						"          {Ship Mode} = sample_data_south.{Shipping Method},",
						"          {Customer ID} = sample_data_south.{Customer Number},",
						"          Segment = sample_data_south.Segment,",
						"          {Postal Code} = sample_data_south.{Postal Code 1},",
						"          {Product ID} = sample_data_south.{Product ID},",
						"          Sales = sample_data_south.Sales,",
						"          Quantity = sample_data_south.Quantity,",
						"          Discount = sample_data_south.Discount,",
						"          Profit = sample_data_south.Profit,",
						"          Source_File",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> FlattenandRenameColumns",
						"FlattenandRenameColumns, ReadSegmentAllowed join(fuzzyCompare(Segment, {Segment Allowed}, 85.00),",
						"     joinType:'left',",
						"     matchType:'fuzzy',",
						"     ignoreSpaces: true,",
						"     broadcast: 'off')~> MergeSegment",
						"MergeSegment, ReadShipModeAllowed join(fuzzyCompare({Ship Mode}, {Ship Mode Allowed}, 85.00),",
						"     joinType:'left',",
						"     matchType:'fuzzy',",
						"     ignoreSpaces: true,",
						"     broadcast: 'off')~> MergeShipMode",
						"AddErrorRoes derive(DuplicateRowCount = iif(isNull(DuplicateRowCount),0,toInteger(DuplicateRowCount)),",
						"          ErrorRowCount = iif(isNull(ErrorRowCount),0,toInteger(ErrorRowCount))) ~> FixNullValues",
						"RemoveDuplicates sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Order_ID as string,",
						"          Order_Date as date,",
						"          Ship_Date as date,",
						"          Ship_Mode as string,",
						"          Customer_ID as string,",
						"          Segment as string,",
						"          Postal_Code as integer,",
						"          Product_ID as string,",
						"          SALES as decimal(20,2),",
						"          QUANTITY as integer,",
						"          Discount as double,",
						"          Profit as double,",
						"          Create_Timestamp as timestamp,",
						"          SOURCE_FILE as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'allErrors',",
						"     outputRejectedData: true,",
						"     rejectedData_container: 'tes-rawdata',",
						"     rejectedData_folderPath: 'Rows_to_be_Fixed',",
						"     transactionCommit: 'single',",
						"     reportSuccessOnError: false,",
						"     mapColumn(",
						"          Order_ID = {Order ID},",
						"          Order_Date = {Order Date Converted},",
						"          Ship_Date = {Ship Date Converted},",
						"          Ship_Mode = {Ship Mode Allowed},",
						"          Customer_ID = {Customer ID},",
						"          Segment = {Segment Allowed},",
						"          Postal_Code = {Postal Code Converted},",
						"          Product_ID = {Product ID},",
						"          SALES = {Sales Converted},",
						"          QUANTITY = {Quantity Converted},",
						"          Discount = {Discount Converted},",
						"          Profit = {Profit Converted},",
						"          Create_Timestamp = TimeStamp,",
						"          SOURCE_FILE = Source_File",
						"     )) ~> InsertinSQL",
						"RowswithNulls@Ignore sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Column_1 as string,",
						"          Column_2 as string,",
						"          Column_3 as string,",
						"          Column_4 as string,",
						"          Column_5 as string,",
						"          Column_6 as string,",
						"          Column_7 as string,",
						"          Column_8 as string,",
						"          Column_9 as string,",
						"          Column_10 as string,",
						"          Column_11 as string,",
						"          Column_12 as string",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> InsertinCSV",
						"FixNullValues sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          SOURCE_FILE as string,",
						"          TIMESTAMP as timestamp,",
						"          SOURCE_ROW_COUNT as integer,",
						"          ERROR_ROWS as integer,",
						"          DUPLICATE_ROW_COUNT as integer,",
						"          FINAL_COUNT as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          SOURCE_FILE = SourceRowCount@Source_File,",
						"          TIMESTAMP = SourceRowCount@TimeStamp,",
						"          SOURCE_ROW_COUNT = RowCount,",
						"          ERROR_ROWS = ErrorRowCount,",
						"          DUPLICATE_ROW_COUNT = DuplicateRowCount",
						"     )) ~> AddLogs"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/SouthSource')]",
				"[concat(variables('factoryId'), '/datasets/DatavalidationSegment')]",
				"[concat(variables('factoryId'), '/datasets/DatavalidationShipMode')]",
				"[concat(variables('factoryId'), '/datasets/SalesSQL')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]",
				"[concat(variables('factoryId'), '/datasets/DumpRowstobeFixed')]",
				"[concat(variables('factoryId'), '/datasets/SalesLogsSQL')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/WestDataMigrate')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "WestSource",
								"type": "DatasetReference"
							},
							"name": "ReadSource"
						},
						{
							"dataset": {
								"referenceName": "DatavalidationSegment",
								"type": "DatasetReference"
							},
							"name": "ReadSegmentAllowed"
						},
						{
							"dataset": {
								"referenceName": "DatavalidationShipMode",
								"type": "DatasetReference"
							},
							"name": "ReadShipModeAllowed"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "SalesSQL",
								"type": "DatasetReference"
							},
							"name": "InsertinSQL",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "DumpRowstobeFixed",
								"type": "DatasetReference"
							},
							"name": "InsertinCSV"
						},
						{
							"dataset": {
								"referenceName": "SalesLogsSQL",
								"type": "DatasetReference"
							},
							"name": "AddLogs"
						}
					],
					"transformations": [
						{
							"name": "RemoveDuplicates"
						},
						{
							"name": "RowswithNulls"
						},
						{
							"name": "AddColumns"
						},
						{
							"name": "SourceRowCount"
						},
						{
							"name": "ErrorRowCount"
						},
						{
							"name": "DuplicateRowCount"
						},
						{
							"name": "RenameColumns"
						},
						{
							"name": "AddDuplicateRows"
						},
						{
							"name": "AddErrorRows"
						},
						{
							"name": "MergeSegment"
						},
						{
							"name": "MergeShipMode"
						},
						{
							"name": "FixNullValues"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Column_1 as string,",
						"          Column_2 as string,",
						"          Column_3 as string,",
						"          Column_4 as string,",
						"          Column_5 as string,",
						"          Column_6 as string,",
						"          Column_7 as string,",
						"          Column_8 as string,",
						"          Column_9 as string,",
						"          Column_10 as string,",
						"          Column_11 as string,",
						"          Column_12 as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false,",
						"     rowUrlColumn: 'Source_File',",
						"     wildcardPaths:['West_Data/*.xlsx'],",
						"     mode: 'read') ~> ReadSource",
						"source(output(",
						"          {Segment Allowed} as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadSegmentAllowed",
						"source(output(",
						"          {Ship Mode Allowed} as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> ReadShipModeAllowed",
						"RowswithNulls@Retain aggregate(groupBy({Order ID},",
						"          {Ship Mode Allowed},",
						"          {Customer ID},",
						"          {Segment Allowed},",
						"          {Product ID},",
						"          Source_File,",
						"          TimeStamp,",
						"          {Order Date Converted},",
						"          {Ship Date Converted},",
						"          {Postal Code Converted},",
						"          {Sales Converted},",
						"          {Quantity Converted},",
						"          {Discount Converted},",
						"          {Profit Converted}),",
						"     Dummy = sum(1)) ~> RemoveDuplicates",
						"AddColumns split(!isNull({Order ID}) && !isNull({Order Date Converted}) && !isNull({Ship Date Converted}) && !isNull({Ship Mode Allowed}) && !isNull({Customer ID}) && !isNull({Segment Allowed}) && !isNull({Postal Code Converted}) && !isNull({Product ID}) && !isNull({Sales Converted}) && !isNull({Quantity Converted}) && !isNull({Discount Converted}) && !isNull({Profit Converted}),",
						"     disjoint: false) ~> RowswithNulls@(Retain, Ignore)",
						"MergeShipMode derive(TimeStamp = currentUTC(),",
						"          {Order Date Converted} = toDate({Order Date},'yyyy-MM-dd'),",
						"          {Ship Date Converted} = iif(startsWith({Ship Date}, '32'),toDate(replace({Ship Date},'32','30'),'dd/MM/yyyy'),toDate({Ship Date},'yyyy-MM-dd')),",
						"          {Postal Code Converted} = toInteger({Postal Code}),",
						"          {Sales Converted} = toDouble(Sales),",
						"          {Quantity Converted} = toInteger(regexReplace(Quantity,'[^.0-9]','')),",
						"          {Discount Converted} = round(toFloat(Discount),2),",
						"          {Profit Converted} = round(toFloat(Profit),2),",
						"          {Product ID} = replace({Product ID},'*','')) ~> AddColumns",
						"AddColumns aggregate(groupBy(Source_File,",
						"          TimeStamp),",
						"     RowCount = sum(1)) ~> SourceRowCount",
						"RowswithNulls@Ignore aggregate(groupBy(Source_File,",
						"          TimeStamp),",
						"     ErrorRowCount = sum(1)) ~> ErrorRowCount",
						"RemoveDuplicates aggregate(groupBy(Source_File,",
						"          TimeStamp),",
						"     DuplicateRowCount = sum(iif(Dummy != 1, Dummy - 1, toLong(0)))) ~> DuplicateRowCount",
						"ReadSource select(mapColumn(",
						"          {Order ID} = Column_1,",
						"          {Order Date} = Column_2,",
						"          {Ship Date} = Column_3,",
						"          {Ship Mode} = Column_4,",
						"          {Customer ID} = Column_5,",
						"          Segment = Column_6,",
						"          {Postal Code} = Column_7,",
						"          {Product ID} = Column_8,",
						"          Sales = Column_9,",
						"          Quantity = Column_10,",
						"          Discount = Column_11,",
						"          Profit = Column_12,",
						"          Source_File",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RenameColumns",
						"SourceRowCount, DuplicateRowCount join(SourceRowCount@Source_File == DuplicateRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> AddDuplicateRows",
						"AddDuplicateRows, ErrorRowCount join(SourceRowCount@Source_File == ErrorRowCount@Source_File,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> AddErrorRows",
						"RenameColumns, ReadSegmentAllowed join(fuzzyCompare(Segment, {Segment Allowed}, 85.00),",
						"     joinType:'left',",
						"     matchType:'fuzzy',",
						"     ignoreSpaces: true,",
						"     broadcast: 'off')~> MergeSegment",
						"MergeSegment, ReadShipModeAllowed join(fuzzyCompare({Ship Mode}, {Ship Mode Allowed}, 85.00),",
						"     joinType:'left',",
						"     matchType:'fuzzy',",
						"     ignoreSpaces: true,",
						"     broadcast: 'off')~> MergeShipMode",
						"AddErrorRows derive(DuplicateRowCount = iif(isNull(DuplicateRowCount),0,toInteger(DuplicateRowCount)),",
						"          ErrorRowCount = iif(isNull(ErrorRowCount),0,toInteger(ErrorRowCount))) ~> FixNullValues",
						"RemoveDuplicates sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Order_ID as string,",
						"          Order_Date as date,",
						"          Ship_Date as date,",
						"          Ship_Mode as string,",
						"          Customer_ID as string,",
						"          Segment as string,",
						"          Postal_Code as integer,",
						"          Product_ID as string,",
						"          SALES as decimal(20,2),",
						"          QUANTITY as integer,",
						"          Discount as double,",
						"          Profit as double,",
						"          Create_Timestamp as timestamp,",
						"          SOURCE_FILE as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'allErrors',",
						"     outputRejectedData: true,",
						"     rejectedData_container: 'tes-rawdata',",
						"     rejectedData_folderPath: 'Rows_to_be_Fixed',",
						"     transactionCommit: 'single',",
						"     reportSuccessOnError: false,",
						"     mapColumn(",
						"          Order_ID = {Order ID},",
						"          Order_Date = {Order Date Converted},",
						"          Ship_Date = {Ship Date Converted},",
						"          Ship_Mode = {Ship Mode Allowed},",
						"          Customer_ID = {Customer ID},",
						"          Segment = {Segment Allowed},",
						"          Postal_Code = {Postal Code Converted},",
						"          Product_ID = {Product ID},",
						"          SALES = {Sales Converted},",
						"          QUANTITY = {Quantity Converted},",
						"          Discount = {Discount Converted},",
						"          Profit = {Profit Converted},",
						"          Create_Timestamp = TimeStamp,",
						"          SOURCE_FILE = Source_File",
						"     )) ~> InsertinSQL",
						"RowswithNulls@Ignore sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Column_1 as string,",
						"          Column_2 as string,",
						"          Column_3 as string,",
						"          Column_4 as string,",
						"          Column_5 as string,",
						"          Column_6 as string,",
						"          Column_7 as string,",
						"          Column_8 as string,",
						"          Column_9 as string,",
						"          Column_10 as string,",
						"          Column_11 as string,",
						"          Column_12 as string",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> InsertinCSV",
						"FixNullValues sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          SOURCE_FILE as string,",
						"          TIMESTAMP as timestamp,",
						"          SOURCE_ROW_COUNT as integer,",
						"          ERROR_ROWS as integer,",
						"          DUPLICATE_ROW_COUNT as integer,",
						"          FINAL_COUNT as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          SOURCE_FILE = SourceRowCount@Source_File,",
						"          TIMESTAMP = SourceRowCount@TimeStamp,",
						"          SOURCE_ROW_COUNT = RowCount,",
						"          DUPLICATE_ROW_COUNT = DuplicateRowCount,",
						"          ERROR_ROWS = ErrorRowCount",
						"     )) ~> AddLogs"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/WestSource')]",
				"[concat(variables('factoryId'), '/datasets/DatavalidationSegment')]",
				"[concat(variables('factoryId'), '/datasets/DatavalidationShipMode')]",
				"[concat(variables('factoryId'), '/datasets/SalesSQL')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureBlobStorage1')]",
				"[concat(variables('factoryId'), '/datasets/DumpRowstobeFixed')]",
				"[concat(variables('factoryId'), '/datasets/SalesLogsSQL')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/default')]",
			"type": "Microsoft.DataFactory/factories/managedVirtualNetworks",
			"apiVersion": "2018-06-01",
			"properties": {},
			"dependsOn": []
		}
	]
}